<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Hyper-Parameter-Tunning">Hyper Parameter Tunning<a class="anchor-link" href="#Hyper-Parameter-Tunning">&#182;</a></h1><p>머신러닝 알고리즘을 통해 학습을 진행할 때, 알고리즘의 다양한 파라미터를 통해 데이터에 대한 최적의 모델을 찾는 과정이 필요합니다. 메뉴얼한 방식으로 대략적인 알고리즘의 선택을 할 수는 있지만, 최적의 모델을 선택하기 위해서는 다양한 파라미터 조합을 통한 많은 학습이 필요하게 됩니다. 데이터 수, 피처 수, 파라미터 조합에 따라 최적화 수행 시간은 기하 급수적으로 늘어나게 됩니다.</p>
<h2 id="Scikit-Learn">Scikit-Learn<a class="anchor-link" href="#Scikit-Learn">&#182;</a></h2><h3 id="Grid-Search-&amp;-Randomized-Search">Grid Search &amp; Randomized Search<a class="anchor-link" href="#Grid-Search-&amp;-Randomized-Search">&#182;</a></h3><p>파라미터에 의해서 생성할 수 있는 모든 파라미터의 조합을 생성하여 최적화 파라미터를 찾습니다. 전수를 테스트하는 Grid Search 방식은 Search Space 가 크기 때문에 조금만 파라미터가 커치면 학습해야하는 조합이 늘게 됩니다. 그래서 이보다는 모든 조합을 시도하는 대신 모든 반복에서 각 파라미터에 대해 랜덤 값을 선택하여 학습 조합 수를 줄이는 Randomized Search 방식이 자주 사용됩니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">model_selection</span><span class="p">,</span> <span class="n">svm</span><span class="p">,</span> <span class="n">metrics</span>
<span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">joblib</span>

<span class="c1"># 데이터</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">np_data_xs</span><span class="p">,</span> <span class="n">np_data_ys</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_classification</span><span class="p">(</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span> <span class="c1"># 데이터 수</span>
    <span class="n">n_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="c1"># X feature 수</span>
    <span class="n">n_informative</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">n_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="c1"># Y class 수</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># 난수 발생용 Seed 값</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;data shape: np_data_xs=</span><span class="si">{}</span><span class="s2">, np_data_ys=</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np_data_xs</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">np_data_ys</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">np_train_xs</span><span class="p">,</span> <span class="n">np_test_xs</span><span class="p">,</span> <span class="n">np_train_ys</span><span class="p">,</span> <span class="n">np_test_ys</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">np_data_xs</span><span class="p">,</span> <span class="n">np_data_ys</span><span class="p">,</span> 
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Set the parameters by cross-validation</span>
<span class="n">tuned_parameters</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;rbf&#39;</span><span class="p">],</span> <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">],</span> <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">]},</span>
    <span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">],</span> <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">]}</span>
<span class="p">]</span>

<span class="n">scores</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">,</span> <span class="s1">&#39;recall&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;# Tuning hyper-parameters for </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">score</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">()</span>

    <span class="c1">#clf = model_selection.GridSearchCV(svm.SVC(), tuned_parameters, scoring=&#39;%s_macro&#39; % score, n_jobs=-1)</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(),</span> <span class="n">tuned_parameters</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%s</span><span class="s1">_macro&#39;</span> <span class="o">%</span> <span class="n">score</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np_train_xs</span><span class="p">,</span> <span class="n">np_train_ys</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best parameters set found on development set:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best estimator set found on development set:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Grid scores on development set:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="n">means</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]</span>
    <span class="n">stds</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;std_test_score&#39;</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">mean</span><span class="p">,</span> <span class="n">std</span><span class="p">,</span> <span class="n">params</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">means</span><span class="p">,</span> <span class="n">stds</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">]):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%0.3f</span><span class="s2"> (+/-</span><span class="si">%0.03f</span><span class="s2">) for </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">std</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">params</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Detailed classification report:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The model is trained on the full development set.&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The scores are computed on the full evaluation set.&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
    <span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span> <span class="o">=</span> <span class="n">np_test_ys</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np_test_xs</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>data shape: np_data_xs=(1000, 10), np_data_ys=(1000,)
# Tuning hyper-parameters for precision

Best parameters set found on development set:

{&#39;kernel&#39;: &#39;rbf&#39;, &#39;gamma&#39;: 0.001, &#39;C&#39;: 1000}

Best estimator set found on development set:

SVC(C=1000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovr&#39;, degree=3, gamma=0.001, kernel=&#39;rbf&#39;,
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)

Grid scores on development set:

0.895 (+/-0.043) for {&#39;kernel&#39;: &#39;rbf&#39;, &#39;gamma&#39;: 0.001, &#39;C&#39;: 1000}
0.880 (+/-0.042) for {&#39;kernel&#39;: &#39;linear&#39;, &#39;C&#39;: 1000}
0.885 (+/-0.055) for {&#39;kernel&#39;: &#39;rbf&#39;, &#39;gamma&#39;: 0.001, &#39;C&#39;: 100}
0.880 (+/-0.042) for {&#39;kernel&#39;: &#39;linear&#39;, &#39;C&#39;: 100}
0.872 (+/-0.076) for {&#39;kernel&#39;: &#39;rbf&#39;, &#39;gamma&#39;: 0.001, &#39;C&#39;: 10}
0.876 (+/-0.049) for {&#39;kernel&#39;: &#39;linear&#39;, &#39;C&#39;: 1}
0.443 (+/-0.043) for {&#39;kernel&#39;: &#39;rbf&#39;, &#39;gamma&#39;: 0.0001, &#39;C&#39;: 1}
0.882 (+/-0.056) for {&#39;kernel&#39;: &#39;rbf&#39;, &#39;gamma&#39;: 0.0001, &#39;C&#39;: 1000}
0.880 (+/-0.046) for {&#39;kernel&#39;: &#39;linear&#39;, &#39;C&#39;: 10}
0.842 (+/-0.072) for {&#39;kernel&#39;: &#39;rbf&#39;, &#39;gamma&#39;: 0.0001, &#39;C&#39;: 10}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

              precision    recall  f1-score   support

           0       0.94      0.92      0.93        88
           1       0.91      0.84      0.88       114
           2       0.85      0.95      0.90        98

    accuracy                           0.90       300
   macro avg       0.90      0.90      0.90       300
weighted avg       0.90      0.90      0.90       300


# Tuning hyper-parameters for recall

Best parameters set found on development set:

{&#39;kernel&#39;: &#39;rbf&#39;, &#39;gamma&#39;: 0.001, &#39;C&#39;: 1000}

Best estimator set found on development set:

SVC(C=1000, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape=&#39;ovr&#39;, degree=3, gamma=0.001, kernel=&#39;rbf&#39;,
    max_iter=-1, probability=False, random_state=None, shrinking=True,
    tol=0.001, verbose=False)

Grid scores on development set:

0.868 (+/-0.080) for {&#39;kernel&#39;: &#39;rbf&#39;, &#39;gamma&#39;: 0.0001, &#39;C&#39;: 100}
0.870 (+/-0.080) for {&#39;kernel&#39;: &#39;rbf&#39;, &#39;gamma&#39;: 0.001, &#39;C&#39;: 10}
0.837 (+/-0.073) for {&#39;kernel&#39;: &#39;rbf&#39;, &#39;gamma&#39;: 0.0001, &#39;C&#39;: 10}
0.881 (+/-0.063) for {&#39;kernel&#39;: &#39;rbf&#39;, &#39;gamma&#39;: 0.001, &#39;C&#39;: 100}
0.877 (+/-0.047) for {&#39;kernel&#39;: &#39;linear&#39;, &#39;C&#39;: 1000}
0.835 (+/-0.069) for {&#39;kernel&#39;: &#39;rbf&#39;, &#39;gamma&#39;: 0.001, &#39;C&#39;: 1}
0.877 (+/-0.051) for {&#39;kernel&#39;: &#39;linear&#39;, &#39;C&#39;: 10}
0.873 (+/-0.053) for {&#39;kernel&#39;: &#39;linear&#39;, &#39;C&#39;: 1}
0.878 (+/-0.061) for {&#39;kernel&#39;: &#39;rbf&#39;, &#39;gamma&#39;: 0.0001, &#39;C&#39;: 1000}
0.891 (+/-0.048) for {&#39;kernel&#39;: &#39;rbf&#39;, &#39;gamma&#39;: 0.001, &#39;C&#39;: 1000}

Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

              precision    recall  f1-score   support

           0       0.94      0.92      0.93        88
           1       0.91      0.84      0.88       114
           2       0.85      0.95      0.90        98

    accuracy                           0.90       300
   macro avg       0.90      0.90      0.90       300
weighted avg       0.90      0.90      0.90       300


</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
 

