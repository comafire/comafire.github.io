{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전 글에서 Jupyter를 설치하고 Pelican을 이용하여 블로깅에 사용할수 있는 방법에 대해알아봤습니다.\n",
    "[Jupyter-From-Dev-To-Blogging](https://comafire.github.io/posts/2016-Jupyter-From-Dev-To-Blogging)\n",
    "\n",
    "이제 Jupyter 에서 로컬 노트북상에 Apache Spark을 사용할 수 있도록 연동해 보도록 하겠습니다. \n",
    "\n",
    "<!-- TEASER_END -->\n",
    "\n",
    "### Apache Spark\n",
    "\n",
    "Spark으로 무엇을 해보려면 클러스터가 있어야 한다는 선입견에 빠지기 쉽습니다만, 요즘 보편화 되어 있는 멀티 코어 노트북의 장점을 복잡한 멀티코어, 멀티스레드 프로그래밍 없이 적극 활용가능하다는 측면에서 클러스터가 아닌 로컬 노트북상에서도 충분한 활용성이 있습니다.\n",
    "\n",
    "먼저, Java 가 설치되어 있는지 확인합니다. \n",
    "\n",
    "```bash\n",
    "> which java\n",
    "/usr/bin/java\n",
    "> java -version\n",
    "java version \"1.8.0_91\"\n",
    "Java(TM) SE Runtime Environment (build 1.8.0_91-b14)\n",
    "Java HotSpot(TM) 64-Bit Server VM (build 25.91-b14, mixed mode)\n",
    "```\n",
    "\n",
    "만약 설치가 안되어 있으면  http://www.oracle.com/technetwork/java/javase/downloads/index.html 오라클 홈페이지 상에서 다운받아 설치합니다.\n",
    "\n",
    "\n",
    "다음으로 brew 를 이용하여 scala 를 설치합니다.\n",
    "\n",
    "```bash\n",
    "> brew install scala\n",
    "```\n",
    "\n",
    "이제 Spark을 설치합니다. https://spark.apache.org/downloads.html 사이트에서 원하는 버전의 Spark 을 다운로드 받습니다.\n",
    "\n",
    "로컬에 Spark을 설치하는 것은 간단히 Spark을 받아 압축을 푸는 것으로 끝납니다. 편의를 위해서 심볼릭 링크를 걸어둡니다.\n",
    "\n",
    "```bash\n",
    "> cd /usr/local\n",
    "> mv ~/Downloads/spark-2.0.0-bin-hadoop2.7.tgz ./\n",
    "> tar -zxvf spark-2.0.0-bin-hadoop2.7.tgz\n",
    "> ln -s spark-2.0.0-bin-hadoop2.7 spark\n",
    "```\n",
    "\n",
    "이제 쉘 환경설정파일에 환경변수를 설정합니다.\n",
    "\n",
    "```\n",
    "> vi ~/.bash_profile\n",
    "\n",
    "export PATH=\"/usr/local/sbin:$PATH\"\n",
    "\n",
    "export JAVA_HOME=$(/usr/libexec/java_home)\n",
    "export SCALA_HOME=/usr/local/bin/scala\n",
    "export PATH=$PATH:$SCALA_HOME/bin\n",
    "\n",
    "export SPARK_HOME=/usr/local/spark\n",
    "export PATH=$PATH:$SPARK_HOME/bin\n",
    "export PYTHONPATH=$SPARK_HOME/python/:$PYTHONPATH\n",
    "export PYTHONPATH=$SPARK_HOME/python/lib/py4j-0.10-src.zip:$PYTHONPATH\n",
    "\n",
    "export PYTHON=/usr/local/bin/python\n",
    "```\n",
    "py4j 라이브러리의 경우 설치한 spark 안에 라이브러리 버전을 확인하여 이름을 넣어주세요.\n",
    "\n",
    "\n",
    "이제 Jupyter 와 연동하기 위해 Apache Toree를 설치합니다. 기존에 Jupyter와 Spark을 연결하는 방식이 좀 복잡했는데 Toree 를 이용하면 간단하게 Jupyter 와 연동이 가능합니다.\n",
    "\n",
    "```bash\n",
    "> pip install --pre toree\n",
    "> jupyter toree install\n",
    "```\n",
    "\n",
    "이제 지금 블로깅하고 있는 Jupyter의 Kernel을 Toree리로 변경하고 간단히 로컬에 설치된 Spark를 테스트해보겠습니다.\n",
    "\n",
    "먼저 Scala를 통해 Spark소스안에 포함된 예제 json 파일을 dataframe으로 읽어보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.sql.SQLContext\n",
    "\n",
    "val df = sqlContext.read.json(\"/usr/local/spark/examples/src/main/resources/people.json\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 Toree의 Magics 통해 Python과 R로 Spark을 사용해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+----+-------+\n",
       "| age|   name|\n",
       "+----+-------+\n",
       "|null|Michael|\n",
       "|  30|   Andy|\n",
       "|  19| Justin|\n",
       "+----+-------+\n",
       "\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%PySpark\n",
    "df = sqlContext.read.json(\"/usr/local/spark/examples/src/main/resources/people.json\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 외에도 다양한 Magics를 지원합니다. 더 자세한 사용법은 아래 링크를 참조하세요.\n",
    "https://github.com/apache/incubator-toree/blob/master/etc/examples/notebooks/magic-tutorial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+----+-------+\n",
       "| age|   name|\n",
       "+----+-------+\n",
       "|null|Michael|\n",
       "|  30|   Andy|\n",
       "|  19| Justin|\n",
       "+----+-------+"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%SparkR\n",
    "df <- jsonFile(sqlContext, \"/usr/local/spark/examples/src/main/resources/people.json\")\n",
    "showDF(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한가지 아쉬운 점은 Toree 내에서 Python과 R의 경우 코드 자동완성 기능이 Spark함수 밖에 안된다는 것입니다.\n",
    "\n",
    "Python과 R의 경우 따로 Python과 R커널에서 Spark을 띄워서 사용하면 Spark외 함수에 대한 코드 자동완성 기능을 사용할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  },
  "nikola": {
   "category": "",
   "date": "2016-01-01 00:00:00 UTC+09:00",
   "description": "",
   "link": "",
   "slug": "2016-Jupyter-Spark",
   "tags": "",
   "title": "Jupyter 노트북에서 Spark사용하기",
   "type": "text"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
