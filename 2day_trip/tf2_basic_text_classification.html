
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>TF2 기본 텍스트 분류 &#8212; 데사견문록</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="TF2 Hub로 텍스트 분류" href="tf2_hub_text_classification.html" />
    <link rel="prev" title="TF2 기본 이미지 분류" href="tf2_basic_image_classification.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">데사견문록</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../readme.html">
   데이터사이언스견문록
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../1day_trip/readme.html">
   당일치기 편
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/e2eds.html">
     End to End Data Science (E2EDS)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/infra.html">
     인프라
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/jupyter_cloud.html">
     Jupyter (Cloud)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/random_seed.html">
     Random
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/pandas_10mins.html">
     Pandas 10분만에 훑어보기
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/numpy_10mins.html">
     Numpy 10분만에 훑어보기
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/data_description.html">
     데이터 서술
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/missing_value.html">
     결측치
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/descriptive_statistics.html">
     기술 통계
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/outlier.html">
     이상치
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/feature_selection.html">
     변수 선택
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/feature_extraction.html">
     변수 추출
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/feature_transformation.html">
     변수 변형
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/normality_test.html">
     정규성 검정
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/statistics_test.html">
     통계적 검정
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/parallel_algorithm.html">
     1-Pass/병렬 알고리즘
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/split_train_test.html">
     Train/Valid/Test 데이터 셋 나누기
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/imbalanced_class.html">
     Imbalanced Class
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/model_persistence.html">
     Model Persistence
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/eval_regression.html">
     Regression 평가
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/linear_regression.html">
     Linear Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/polynomial_regression.html">
     Polynomial Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/sgd_regression.html">
     SGD Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/svm_regression.html">
     SVM Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/nearest_neighbor_regression.html">
     Nearest Neighbors Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/ensemble_regression.html">
     Ensemble Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/eval_classification.html">
     Classification 평가
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/logistic_regression.html">
     Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/sgd_classification.html">
     SGD Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/svm_classification.html">
     SVM Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/nearest_neighbor_classification.html">
     Nearest Neighbors Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/ensemble_classification.html">
     Ensemble Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/eval_clustering.html">
     Clustering 평가
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/kmeans.html">
     K-Means
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/mean_shift.html">
     Mean Shift
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1day_trip/spectral_clustering.html">
     Spectral Clustering
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="readme.html">
   주말여행 편
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="jupyter_native_ubuntu.html">
     Jupyter (Ubuntu)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="jupyter_native_macos.html">
     Jupyter (macOS)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="spark_dataframe_10mins.html">
     Spark DataFrame 10분만에 훑어보기
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="keras_10mins.html">
     Keras 10분 만에 훑어보기
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dnn_regression.html">
     DNN Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dnn_classification.html">
     DNN Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="hyper_parameter_tunning.html">
     Hyper Parameter Tunning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="collaborative_filtering.html">
     Collaborative Filtering (CF)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="anomaly_detection.html">
     Anomaly Detection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="tf2_10mins.html">
     Tensorflow2 10분만에 훑어보기
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="tf2_basic_image_classification.html">
     TF2 기본 이미지 분류
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     TF2 기본 텍스트 분류
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="tf2_hub_text_classification.html">
     TF2 Hub로 텍스트 분류
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="tf2_basic_regression.html">
     TF2 회귀
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="tf2_overfit_underfit.html">
     TF2 Overfit Underfit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="tf2_save_load.html">
     TF2 Save Load
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../5day_trip/readme.html">
   단기여행 편
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../5day_trip/infra.html">
     인프라
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5day_trip/jupyter_docker.html">
     Jupyter (Docker)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../5day_trip/vagrant_virtualbox.html">
     Vagrant (Optional)
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../long_trip/readme.html">
   장기여행 편
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/2day_trip/tf2_basic_text_classification.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/executablebooks/comafire.github.io"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/executablebooks/comafire.github.io/issues/new?title=Issue%20on%20page%20%2F2day_trip/tf2_basic_text_classification.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/comafire.github.io/master?urlpath=tree/docs/2day_trip/tf2_basic_text_classification.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   영화 리뷰를 사용한 텍스트 분류
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#imdb">
     IMDB 데이터셋 다운로드
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     데이터 탐색
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     데이터 준비
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     모델 구성
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     손실 함수와 옵티마이저
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id6">
     검증 세트 만들기
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id7">
     모델 훈련
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id8">
   모델 평가
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id9">
     정확도와 손실 그래프 그리기
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="tf2">
<h1>TF2 기본 텍스트 분류<a class="headerlink" href="#tf2" title="Permalink to this headline">¶</a></h1>
<p><a class="reference external" href="https://www.tensorflow.org/tutorials/keras/text_classification?hl=ko">https://www.tensorflow.org/tutorials/keras/text_classification?hl=ko</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 경고 메시지 출력 끄기</span>
<span class="kn">import</span> <span class="nn">warnings</span> 
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="n">action</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>

<span class="c1"># 노트북 셀 표시를 브라우저 전체 폭 사용하기</span>
<span class="kn">from</span> <span class="nn">IPython.core.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>
<span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="s2">&quot;&lt;style&gt;.container { width:100% !important; }&lt;/style&gt;&quot;</span><span class="p">))</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">clear_output</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">sys</span>

<span class="n">rseed</span> <span class="o">=</span> <span class="mi">22</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">rseed</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">rseed</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">formatter</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;float_kind&#39;</span><span class="p">:</span> <span class="s2">&quot;</span><span class="si">{:.5f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">})</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_rows&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> 
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_columns&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> 
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_colwidth&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">float_format</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">{:,.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_seed</span><span class="p">(</span><span class="n">rseed</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">set_floatx</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="c1"># keras default float type 설정</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;python ver=</span><span class="si">{</span><span class="n">sys</span><span class="o">.</span><span class="n">version</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;pandas ver=</span><span class="si">{</span><span class="n">pd</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;numpy ver=</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tensorflow ver=</span><span class="si">{</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>.container { width:100% !important; }</style></div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>python ver=3.7.6 (default, Nov 21 2020, 22:51:13) 
[Clang 12.0.0 (clang-1200.0.32.27)]
pandas ver=1.0.5
numpy ver=1.19.5
tensorflow ver=2.1.0
</pre></div>
</div>
</div>
</div>
<div class="section" id="id1">
<h2>영화 리뷰를 사용한 텍스트 분류<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p>영화 리뷰 텍스트를 긍정(positive) 또는 부정(negative)으로 분류합니다. 이 예제는 binary classification(이진분류) 문제입니다.</p>
<p>여기에서는 인터넷 영화 데이터베이스(Internet Movie Database)에서 수집한 50,000개의 영화 리뷰 텍스트를 담은 IMDB 데이터셋을 사용합니다.
25,000개 리뷰는 훈련용으로, 25,000개는 테스트용으로 나뉘어져 있으며, 훈련 세트와 테스트 세트의 클래스는 균형이 잡혀 있습니다. 즉 긍정적인 리뷰와 부정적인 리뷰의 개수가 동일합니다.</p>
<div class="section" id="imdb">
<h3>IMDB 데이터셋 다운로드<a class="headerlink" href="#imdb" title="Permalink to this headline">¶</a></h3>
<p>매개변수 num_words=10000은 훈련 데이터에서 가장 많이 등장하는 상위 10,000개의 단어를 어휘 사전으로 선택합니다. 데이터 크기를 적당하게 유지하기 위해 드물에 등장하는 단어는 제외하겠습니다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb/load_data</span>
<span class="n">imdb</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">imdb</span>

<span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">imdb</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">num_words</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id2">
<h3>데이터 탐색<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>이 데이터셋의 샘플은 전처리된 정수 배열입니다. 이 정수는 영화 리뷰에 나오는 단어를 나타냅니다. 레이블(label)은 정수 0 또는 1입니다. 0은 부정적인 리뷰이고 1은 긍정적인 리뷰입니다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;shape: train_data=</span><span class="si">{</span><span class="n">train_data</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, train_labels: </span><span class="si">{</span><span class="n">train_labels</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;sample: train_data=</span><span class="si">{</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">, </span><span class="se">\n</span><span class="s2">train_labels: </span><span class="si">{</span><span class="n">train_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># 영화 리뷰들은 길이가 다릅니다. 다음 코드는 첫 번째 리뷰와 두 번째 리뷰에서 단어의 개수를 출력합니다. 신경망의 입력은 길이가 같아야 하기 때문에 나중에 이 문제를 해결하겠습니다.</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;len: sample0=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="si">}</span><span class="s2">, sample1=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>shape: train_data=(25000,), train_labels: (25000,)
sample: train_data=[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32], 
train_labels: 1
len: sample0=218, sample1=189
</pre></div>
</div>
</div>
</div>
<p>정수를 단어로 다시 변환하기</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 단어와 정수 인덱스를 매핑한 딕셔너리</span>
<span class="n">word_index</span> <span class="o">=</span> <span class="n">imdb</span><span class="o">.</span><span class="n">get_word_index</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;len: word_index=</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">word_index</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span> <span class="c1"># 전체 인덱스는 88,584 개 이지만, 이 중 우리는 상위 빈도 10,000 개의 단어만 사용하는 전처리된 데이터 셋을 사용합니다.</span>
    
<span class="c1"># 몇가지 사전 정의된 값을 설정하기 위해 기존 word_index 값을 일괄 조정 후, 앞쪽에 해당 정의된 Key, Value 값을 저장합니다.</span>
<span class="n">word_index</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:(</span><span class="n">v</span><span class="o">+</span><span class="mi">3</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span><span class="n">v</span> <span class="ow">in</span> <span class="n">word_index</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span class="n">word_index</span><span class="p">[</span><span class="s2">&quot;&lt;PAD&gt;&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">word_index</span><span class="p">[</span><span class="s2">&quot;&lt;START&gt;&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">word_index</span><span class="p">[</span><span class="s2">&quot;&lt;UNK&gt;&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># unknown</span>
<span class="n">word_index</span><span class="p">[</span><span class="s2">&quot;&lt;UNUSED&gt;&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">3</span>

<span class="c1"># 역 인덱스를 만들어 정수 배열 데이터를 글로 변환 합니다.</span>
<span class="n">reverse_word_index</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">([(</span><span class="n">value</span><span class="p">,</span> <span class="n">key</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="n">word_index</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span>

<span class="k">def</span> <span class="nf">decode_review</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">reverse_word_index</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="s1">&#39;?&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">text</span><span class="p">])</span>

<span class="n">decode_review</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>len: word_index=88584
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&quot;&lt;START&gt; this film was just brilliant casting location scenery story direction everyone&#39;s really suited the part they played and you could just imagine being there robert &lt;UNK&gt; is an amazing actor and now the same being director &lt;UNK&gt; father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for &lt;UNK&gt; and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also &lt;UNK&gt; to the two little boy&#39;s that played the &lt;UNK&gt; of norman and paul they were just brilliant children are often left out of the &lt;UNK&gt; list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don&#39;t you think the whole story was so lovely because it was true and was someone&#39;s life after all that was shared with us all&quot;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id3">
<h3>데이터 준비<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>리뷰(정수 배열)은 신경망에 주입하기 전에 텐서로 변환되어야 합니다. 변환하는 방법에는 몇 가지가 있습니다:</p>
<p>원-핫 인코딩(one-hot encoding)은 정수 배열을 0과 1로 이루어진 벡터로 변환합니다. 예를 들어 배열 [3, 5]을 인덱스 3과 5만 1이고 나머지는 모두 0인 10,000차원 벡터로 변환할 수 있습니다. 그다음 실수 벡터 데이터를 다룰 수 있는 Dense 레이어를 신경망의 첫 번째 레이어으로 사용합니다. 이 방법은 num_words * num_reviews 크기의 행렬이 필요하기 때문에 메모리를 많이 사용합니다.</p>
<p>다른 방법으로는, 정수 배열의 길이가 모두 같도록 패딩(padding)을 추가해 max_length * num_reviews 크기의 정수 텐서를 만듭니다. 이런 형태의 텐서를 다룰 수 있는 임베딩(embedding) 층을 신경망의 첫 번째 레이어로 사용할 수 있습니다.</p>
<p>이 튜토리얼에서는 두 번째 방식을 사용하겠습니다.</p>
<p>영화 리뷰의 길이가 같아야 하므로 <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences?hl=ko">pad_sequences</a> 함수를 사용해 길이를 맞춥니다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># padding=&#39;post&#39;: padding을 뒷쪽에 넣어줌</span>
<span class="c1"># value=word_index[&quot;&lt;PAD&gt;&quot;]: word_index[&quot;&lt;PAD&gt;&quot;] 값인 0을 넣어줌</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">sequence</span><span class="o">.</span><span class="n">pad_sequences</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">word_index</span><span class="p">[</span><span class="s2">&quot;&lt;PAD&gt;&quot;</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;post&#39;</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">sequence</span><span class="o">.</span><span class="n">pad_sequences</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">word_index</span><span class="p">[</span><span class="s2">&quot;&lt;PAD&gt;&quot;</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;post&#39;</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(256, 256)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word_index</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[   1   14   22   16   43  530  973 1622 1385   65  458 4468   66 3941
    4  173   36  256    5   25  100   43  838  112   50  670    2    9
   35  480  284    5  150    4  172  112  167    2  336  385   39    4
  172 4536 1111   17  546   38   13  447    4  192   50   16    6  147
 2025   19   14   22    4 1920 4613  469    4   22   71   87   12   16
   43  530   38   76   15   13 1247    4   22   17  515   17   12   16
  626   18    2    5   62  386   12    8  316    8  106    5    4 2223
 5244   16  480   66 3785   33    4  130   12   16   38  619    5   25
  124   51   36  135   48   25 1415   33    6   22   12  215   28   77
   52    5   14  407   16   82    2    8    4  107  117 5952   15  256
    4    2    7 3766    5  723   36   71   43  530  476   26  400  317
   46    7    4    2 1029   13  104   88    4  381   15  297   98   32
 2071   56   26  141    6  194 7486   18    4  226   22   21  134  476
   26  480    5  144   30 5535   18   51   36   28  224   92   25  104
    4  226   65   16   38 1334   88   12   16  283    5   16 4472  113
  103   32   15   16 5345   19  178   32    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0    0    0    0    0    0    0    0    0    0    0
    0    0    0    0]
88588
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id4">
<h3>모델 구성<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>신경망은 레이어(layer)을 쌓아서 만듭니다. 이 구조에서는 두 가지를 결정해야 합니다:</p>
<ul class="simple">
<li><p>모델에서 얼마나 많은 레이어를 사용할 것인가?</p></li>
<li><p>각 레이어에서 얼마나 많은 히든 유닛(hidden unit)을 사용할 것인가?</p></li>
</ul>
<p>이 예제의 입력 데이터는 단어 인덱스의 배열입니다. 예측할 레이블은 0 또는 1입니다. 이 문제에 맞는 모델을 구성합니다.</p>
<p>레이어를 순서대로 쌓아 분류기(classifier)를 만듭니다:</p>
<ul class="simple">
<li><p>첫 번째 레이어는 Embedding 레이어입니다. 이 층은 정수로 인코딩된 단어를 입력 받고 각 단어 인덱스에 해당하는 임베딩 벡터를 찾습니다. 이 벡터는 모델이 훈련되면서 학습됩니다. 이 벡터는 출력 배열에 새로운 차원으로 추가됩니다. 최종 차원은 (batch, sequence, embedding)이 됩니다.</p></li>
<li><p>두 번째 레이어는 GlobalAveragePooling1D 레이어입니다. sequence 차원에 대해 평균을 계산하여 각 샘플에 대해 고정된 길이의 출력 벡터를 반환합니다. 이는 길이가 다른 입력을 다루는 가장 간단한 방법입니다.</p></li>
<li><p>세 번째 레이어는 16개의 은닉 유닛을 가진 완전 연결(fully-connected) Dense 레이어를 거칩니다.</p></li>
<li><p>마지막 레이어는 1 output 을 가지는 Dense 레이어입니다. sigmoid 활성화 함수를 사용하여 0과 1 사이의 실수를 출력합니다. 이 값은 확률 또는 신뢰도를 나타냅니다.</p></li>
</ul>
<p><strong>은닉 유닛</strong></p>
<p>위 모델에는 입력과 출력 사이에 두 개의 중간 또는 “은닉” 레이어가 있습니다. 출력(유닛 또는 노드, 뉴런)의 개수는 레이어가 가진 표현 공간(representational space)의 차원이 됩니다. 다른 말로 하면, 내부 표현을 학습할 때 허용되는 네트워크 자유도의 양입니다.</p>
<p>모델에 많은 은닉 유닛(고차원의 표현 공간)과 레이어가 있다면 네트워크는 더 복잡한 표현을 학습할 수 있습니다. 하지만 네트워크의 계산 비용이 많이 들고 원치않는 패턴을 학습할 수도 있습니다. 이런 표현은 훈련 데이터의 성능을 향상시키지만 테스트 데이터에서는 그렇지 못합니다. 이를 과대적합(overfitting)이라고 부릅니다. 나중에 이에 대해 알아 보겠습니다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 입력 크기는 영화 리뷰 데이터셋에 적용된 어휘 사전의 크기입니다 (빈도 상위: 10,000개의 단어)</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">GlobalAveragePooling1D</span><span class="p">())</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, None, 16)          160000    
_________________________________________________________________
global_average_pooling1d (Gl (None, 16)                0         
_________________________________________________________________
dense (Dense)                (None, 16)                272       
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 17        
=================================================================
Total params: 160,289
Trainable params: 160,289
Non-trainable params: 0
_________________________________________________________________
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id5">
<h3>손실 함수와 옵티마이저<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p>모델이 훈련하려면 손실 함수(loss function)과 옵티마이저(optimizer)가 필요합니다. 이 예제는 이진 분류 문제이고 모델이 확률을 출력하므로(출력층의 유닛이 하나이고 sigmoid 활성화 함수를 사용합니다), binary_crossentropy 손실 함수를 사용하겠습니다.</p>
<p>다른 손실 함수를 선택할 수 없는 것은 아닙니다. 예를 들어 mean_squared_error를 선택할 수 있습니다. 하지만 일반적으로 binary_crossentropy가 확률을 다루는데 적합합니다. 이 함수는 확률 분포 간의 거리를 측정합니다. 여기에서는 정답인 타깃 분포와 예측 분포 사이의 거리입니다.</p>
<p>나중에 회귀(regression) 문제(예를 들어 주택 가격을 예측하는 문제)에 대해 살펴 볼 때 평균 제곱 오차(mean squared error) 손실 함수를 어떻게 사용하는지 알아 보겠습니다.</p>
<p>이제 모델이 사용할 옵티마이저와 손실 함수를 설정해 보겠습니다:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
              <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id6">
<h3>검증 세트 만들기<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<p>모델을 훈련할 때 모델이 만난 적 없는 데이터에서 정확도를 확인하는 것이 좋습니다. 원본 훈련 데이터에서 10,000개의 샘플을 떼어내어 검증 세트(validation set)를 만들겠습니다. (왜 테스트 세트를 사용하지 않을까요? 훈련 데이터만을 사용하여 모델을 개발하고 튜닝하는 것이 목표입니다. 그다음 테스트 세트를 사용해서 딱 한 번만 정확도를 평가합니다).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_val</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[:</span><span class="mi">10000</span><span class="p">]</span>
<span class="n">partial_x_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="mi">10000</span><span class="p">:]</span>

<span class="n">y_val</span> <span class="o">=</span> <span class="n">train_labels</span><span class="p">[:</span><span class="mi">10000</span><span class="p">]</span>
<span class="n">partial_y_train</span> <span class="o">=</span> <span class="n">train_labels</span><span class="p">[</span><span class="mi">10000</span><span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id7">
<h3>모델 훈련<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>이 모델을 512개의 샘플로 이루어진 미니배치(mini-batch)에서 40번의 에포크(epoch) 동안 훈련합니다. x_train과 y_train 텐서에 있는 모든 샘플에 대해 40번 반복한다는 뜻입니다. 훈련하는 동안 10,000개의 검증 세트에서 모델의 손실과 정확도를 모니터링합니다:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">partial_x_train</span><span class="p">,</span>
                    <span class="n">partial_y_train</span><span class="p">,</span>
                    <span class="n">epochs</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
                    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">x_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">),</span>
                    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train on 15000 samples, validate on 10000 samples
Epoch 1/40
15000/15000 [==============================] - 1s 48us/sample - loss: 0.6912 - accuracy: 0.6075 - val_loss: 0.6884 - val_accuracy: 0.6950
Epoch 2/40
15000/15000 [==============================] - 0s 21us/sample - loss: 0.6836 - accuracy: 0.7184 - val_loss: 0.6785 - val_accuracy: 0.6957
Epoch 3/40
15000/15000 [==============================] - 0s 23us/sample - loss: 0.6699 - accuracy: 0.7096 - val_loss: 0.6624 - val_accuracy: 0.7539
Epoch 4/40
15000/15000 [==============================] - 0s 22us/sample - loss: 0.6477 - accuracy: 0.7704 - val_loss: 0.6377 - val_accuracy: 0.7737
Epoch 5/40
15000/15000 [==============================] - 0s 22us/sample - loss: 0.6161 - accuracy: 0.7935 - val_loss: 0.6049 - val_accuracy: 0.7636
Epoch 6/40
15000/15000 [==============================] - 0s 24us/sample - loss: 0.5769 - accuracy: 0.8100 - val_loss: 0.5661 - val_accuracy: 0.8002
Epoch 7/40
15000/15000 [==============================] - 0s 24us/sample - loss: 0.5324 - accuracy: 0.8298 - val_loss: 0.5251 - val_accuracy: 0.8174
Epoch 8/40
15000/15000 [==============================] - 0s 23us/sample - loss: 0.4872 - accuracy: 0.8489 - val_loss: 0.4853 - val_accuracy: 0.8319
Epoch 9/40
15000/15000 [==============================] - 0s 26us/sample - loss: 0.4455 - accuracy: 0.8602 - val_loss: 0.4502 - val_accuracy: 0.8433
Epoch 10/40
15000/15000 [==============================] - 0s 24us/sample - loss: 0.4074 - accuracy: 0.8716 - val_loss: 0.4198 - val_accuracy: 0.8484
Epoch 11/40
15000/15000 [==============================] - 0s 26us/sample - loss: 0.3746 - accuracy: 0.8791 - val_loss: 0.3941 - val_accuracy: 0.8597
Epoch 12/40
15000/15000 [==============================] - 0s 27us/sample - loss: 0.3466 - accuracy: 0.8858 - val_loss: 0.3731 - val_accuracy: 0.8634
Epoch 13/40
15000/15000 [==============================] - 0s 27us/sample - loss: 0.3227 - accuracy: 0.8933 - val_loss: 0.3561 - val_accuracy: 0.8668
Epoch 14/40
15000/15000 [==============================] - 0s 27us/sample - loss: 0.3023 - accuracy: 0.9001 - val_loss: 0.3425 - val_accuracy: 0.8686
Epoch 15/40
15000/15000 [==============================] - 0s 29us/sample - loss: 0.2846 - accuracy: 0.9035 - val_loss: 0.3310 - val_accuracy: 0.8730
Epoch 16/40
15000/15000 [==============================] - 0s 29us/sample - loss: 0.2685 - accuracy: 0.9091 - val_loss: 0.3220 - val_accuracy: 0.8765
Epoch 17/40
15000/15000 [==============================] - 0s 29us/sample - loss: 0.2547 - accuracy: 0.9129 - val_loss: 0.3138 - val_accuracy: 0.8781
Epoch 18/40
15000/15000 [==============================] - 0s 29us/sample - loss: 0.2417 - accuracy: 0.9182 - val_loss: 0.3078 - val_accuracy: 0.8799
Epoch 19/40
15000/15000 [==============================] - 0s 29us/sample - loss: 0.2300 - accuracy: 0.9217 - val_loss: 0.3022 - val_accuracy: 0.8816
Epoch 20/40
15000/15000 [==============================] - 0s 30us/sample - loss: 0.2194 - accuracy: 0.9249 - val_loss: 0.2977 - val_accuracy: 0.8829
Epoch 21/40
15000/15000 [==============================] - 0s 32us/sample - loss: 0.2098 - accuracy: 0.9285 - val_loss: 0.2940 - val_accuracy: 0.8836
Epoch 22/40
15000/15000 [==============================] - 0s 32us/sample - loss: 0.2004 - accuracy: 0.9329 - val_loss: 0.2915 - val_accuracy: 0.8845
Epoch 23/40
15000/15000 [==============================] - 0s 30us/sample - loss: 0.1919 - accuracy: 0.9365 - val_loss: 0.2888 - val_accuracy: 0.8839
Epoch 24/40
15000/15000 [==============================] - 0s 31us/sample - loss: 0.1840 - accuracy: 0.9393 - val_loss: 0.2869 - val_accuracy: 0.8844
Epoch 25/40
15000/15000 [==============================] - 0s 28us/sample - loss: 0.1762 - accuracy: 0.9428 - val_loss: 0.2872 - val_accuracy: 0.8838
Epoch 26/40
15000/15000 [==============================] - 0s 27us/sample - loss: 0.1693 - accuracy: 0.9470 - val_loss: 0.2849 - val_accuracy: 0.8854
Epoch 27/40
15000/15000 [==============================] - 0s 30us/sample - loss: 0.1623 - accuracy: 0.9497 - val_loss: 0.2844 - val_accuracy: 0.8855
Epoch 28/40
15000/15000 [==============================] - 0s 33us/sample - loss: 0.1560 - accuracy: 0.9521 - val_loss: 0.2853 - val_accuracy: 0.8847
Epoch 29/40
15000/15000 [==============================] - 0s 29us/sample - loss: 0.1503 - accuracy: 0.9545 - val_loss: 0.2865 - val_accuracy: 0.8834
Epoch 30/40
15000/15000 [==============================] - 0s 32us/sample - loss: 0.1443 - accuracy: 0.9568 - val_loss: 0.2865 - val_accuracy: 0.8861
Epoch 31/40
15000/15000 [==============================] - 0s 27us/sample - loss: 0.1390 - accuracy: 0.9582 - val_loss: 0.2869 - val_accuracy: 0.8849
Epoch 32/40
15000/15000 [==============================] - 0s 32us/sample - loss: 0.1337 - accuracy: 0.9611 - val_loss: 0.2874 - val_accuracy: 0.8854
Epoch 33/40
15000/15000 [==============================] - 0s 32us/sample - loss: 0.1290 - accuracy: 0.9629 - val_loss: 0.2893 - val_accuracy: 0.8857
Epoch 34/40
15000/15000 [==============================] - 0s 31us/sample - loss: 0.1240 - accuracy: 0.9647 - val_loss: 0.2909 - val_accuracy: 0.8860
Epoch 35/40
15000/15000 [==============================] - 0s 33us/sample - loss: 0.1194 - accuracy: 0.9667 - val_loss: 0.2924 - val_accuracy: 0.8865
Epoch 36/40
15000/15000 [==============================] - 0s 33us/sample - loss: 0.1153 - accuracy: 0.9683 - val_loss: 0.2951 - val_accuracy: 0.8837
Epoch 37/40
15000/15000 [==============================] - 1s 34us/sample - loss: 0.1115 - accuracy: 0.9693 - val_loss: 0.2973 - val_accuracy: 0.8851
Epoch 38/40
15000/15000 [==============================] - 1s 37us/sample - loss: 0.1072 - accuracy: 0.9710 - val_loss: 0.2996 - val_accuracy: 0.8837
Epoch 39/40
15000/15000 [==============================] - 1s 36us/sample - loss: 0.1033 - accuracy: 0.9726 - val_loss: 0.3014 - val_accuracy: 0.8835
Epoch 40/40
15000/15000 [==============================] - 1s 35us/sample - loss: 0.0996 - accuracy: 0.9735 - val_loss: 0.3038 - val_accuracy: 0.8836
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="id8">
<h2>모델 평가<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h2>
<p>모델의 성능을 확인해 보죠. 두 개의 값이 반환됩니다. 손실(오차를 나타내는 숫자이므로 낮을수록 좋습니다)과 정확도입니다. 이 예제는 매우 단순한 방식을 사용하므로 87% 정도의 정확도를 달성했습니다. 고급 방법을 사용한 모델은 95%에 가까운 정확도를 얻습니다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span>  <span class="n">test_labels</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>25000/25000 - 0s - loss: 0.3248 - accuracy: 0.8725
[0.32479287289619446, 0.87252]
</pre></div>
</div>
</div>
</div>
<div class="section" id="id9">
<h3>정확도와 손실 그래프 그리기<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<p>model.fit()은 History 객체를 반환합니다. 여기에는 훈련하는 동안 일어난 모든 정보가 담긴 딕셔너리(dictionary)가 들어 있습니다:</p>
<p>훈련과 검증 단계에서 모니터링하는 지표들입니다. 훈련 손실과 검증 손실을 그래프로 그려 보고, 훈련 정확도와 검증 정확도도 그래프로 그려서 비교해 보겠습니다:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">history_dict</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span>
<span class="n">history_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;loss&#39;, &#39;accuracy&#39;, &#39;val_loss&#39;, &#39;val_accuracy&#39;])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">history_dict</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
<span class="n">val_acc</span> <span class="o">=</span> <span class="n">history_dict</span><span class="p">[</span><span class="s1">&#39;val_accuracy&#39;</span><span class="p">]</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">history_dict</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
<span class="n">val_loss</span> <span class="o">=</span> <span class="n">history_dict</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span>

<span class="n">epochs</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">acc</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># &quot;bo&quot;는 &quot;파란색 점&quot;입니다</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="s1">&#39;bo&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training loss&#39;</span><span class="p">)</span>
<span class="c1"># b는 &quot;파란 실선&quot;입니다</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/tf2_basic_text_classification_25_0.png" src="../_images/tf2_basic_text_classification_25_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">clf</span><span class="p">()</span>   <span class="c1"># 그림을 초기화합니다</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="s1">&#39;bo&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training acc&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation acc&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Training and validation accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epochs&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/tf2_basic_text_classification_26_0.png" src="../_images/tf2_basic_text_classification_26_0.png" />
</div>
</div>
<p>이 그래프에서 점선은 훈련 손실과 훈련 정확도를 나타냅니다. 실선은 검증 손실과 검증 정확도입니다.</p>
<p>훈련 손실은 에포크마다 감소하고 훈련 정확도는 증가한다는 것을 주목하세요. 경사 하강법 최적화를 사용할 때 볼 수 있는 현상입니다. 매 반복마다 최적화 대상의 값을 최소화합니다. 하지만 검증 손실과 검증 정확도에서는 그렇지 못합니다.</p>
<p><strong>약 20번째 에포크 이후가 최적점인 것 같습니다.</strong> 이는 과대적합 때문입니다. 이전에 본 적 없는 데이터보다 훈련 데이터에서 더 잘 동작합니다. 이 지점부터는 모델이 과도하게 최적화되어 테스트 데이터에서 일반화되기 어려운 훈련 데이터의 특정 표현을 학습합니다.</p>
<p>여기에서는 과대적합을 막기 위해 단순히 20번째 에포크 근처에서 훈련을 멈출 수 있습니다. 나중에 콜백(callback)을 사용하여 자동으로 이렇게 하는 방법을 배워 보겠습니다.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># MIT License</span>
<span class="c1">#</span>
<span class="c1"># Copyright (c) 2017 François Chollet</span>
<span class="c1">#</span>
<span class="c1"># Permission is hereby granted, free of charge, to any person obtaining a</span>
<span class="c1"># copy of this software and associated documentation files (the &quot;Software&quot;),</span>
<span class="c1"># to deal in the Software without restriction, including without limitation</span>
<span class="c1"># the rights to use, copy, modify, merge, publish, distribute, sublicense,</span>
<span class="c1"># and/or sell copies of the Software, and to permit persons to whom the</span>
<span class="c1"># Software is furnished to do so, subject to the following conditions:</span>
<span class="c1">#</span>
<span class="c1"># The above copyright notice and this permission notice shall be included in</span>
<span class="c1"># all copies or substantial portions of the Software.</span>
<span class="c1">#</span>
<span class="c1"># THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</span>
<span class="c1"># IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,</span>
<span class="c1"># FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL</span>
<span class="c1"># THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER</span>
<span class="c1"># LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING</span>
<span class="c1"># FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER</span>
<span class="c1"># DEALINGS IN THE SOFTWARE.</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./2day_trip"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="tf2_basic_image_classification.html" title="previous page">TF2 기본 이미지 분류</a>
    <a class='right-next' id="next-link" href="tf2_hub_text_classification.html" title="next page">TF2 Hub로 텍스트 분류</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By comafire<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-81648003-1', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
  </body>
</html>