<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="SGD(Stochastic-Gradient-Descent)-Classification">SGD(Stochastic Gradient Descent) Classification<a class="anchor-link" href="#SGD(Stochastic-Gradient-Descent)-Classification">&#182;</a></h1><p>Stochastic Gradient Descent (SGD) 은 convex 형태의 loss 함수를 통한 최적화 문제에 매우 효율적인 접근방법입니다. SGD는 큰 규모이면서 희소한 형태의 데이터(예로, 10^5 이상의 Feature를 가진 10^5 개 이상의 학습 데이터)에서도 좋은 성과를 나타냅니다.</p>
<p>장점:</p>
<ul>
<li>효율적이며, 구현이 쉬움</li>
</ul>
<p>단점:</p>
<ul>
<li>효율적 학습을 위해 hyperparameters 에 대한 tunning 이 필요</li>
<li>Feature scaling 에 민감</li>
</ul>
<p>SGD에서 살펴볼 주요 파라미터는 loss, penalty, l1_ratio 입니다.</p>
<p>loss</p>
<ul>
<li>loss="hinge": (soft-margin) linear Support Vector Machine,</li>
<li>loss="modified_huber": smoothed hinge loss,</li>
<li>loss="log": logistic regression,</li>
<li>‘squared_hinge’, ‘perceptron’, or a regression loss: ‘squared_loss’, ‘huber’, ‘epsilon_insensitive’, or ‘squared_epsilon_insensitive’</li>
</ul>
<p>penalty</p>
<ul>
<li>penalty="l2": L2 norm penalty on coef_.</li>
<li>penalty="l1": L1 norm penalty on coef_.</li>
<li>penalty="elasticnet": Convex combination of L2 and L1; (1 - l1_ratio) <em> L2 + l1_ratio </em> L1.</li>
</ul>
<p>l1_ratio</p>
<ul>
<li>The Elastic Net mixing parameter, with 0 &lt;= l1_ratio &lt;= 1. l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1. Defaults to 0.15.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">model_selection</span><span class="p">,</span> <span class="n">linear_model</span><span class="p">,</span> <span class="n">metrics</span>

<span class="c1"># 데이터</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">100000</span>
<span class="n">np_data_xs</span><span class="p">,</span> <span class="n">np_data_ys</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_classification</span><span class="p">(</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span> <span class="c1"># 데이터 수</span>
    <span class="n">n_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="c1"># X feature 수</span>
    <span class="n">n_informative</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">n_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="c1"># Y class 수</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># 난수 발생용 Seed 값</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;data shape: np_data_xs=</span><span class="si">{}</span><span class="s2">, np_data_ys=</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np_data_xs</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">np_data_ys</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">np_train_xs</span><span class="p">,</span> <span class="n">np_test_xs</span><span class="p">,</span> <span class="n">np_train_ys</span><span class="p">,</span> <span class="n">np_test_ys</span> <span class="o">=</span> <span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">np_data_xs</span><span class="p">,</span> <span class="n">np_data_ys</span><span class="p">,</span> 
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;train shape: np_train_xs=</span><span class="si">{}</span><span class="s2">, np_train_ys=</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np_train_xs</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">np_train_ys</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;test shape: np_test_xs=</span><span class="si">{}</span><span class="s2">, np_test_ys=</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np_test_xs</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">np_test_ys</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

<span class="c1"># 모델</span>
<span class="n">models</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">linear_model</span><span class="o">.</span><span class="n">SGDClassifier</span><span class="p">()</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
    <span class="c1"># 학습</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;model=</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np_train_xs</span><span class="p">,</span> <span class="n">np_train_ys</span><span class="p">)</span>

    <span class="c1"># 평가</span>
    <span class="n">np_pred_ys</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np_test_xs</span><span class="p">)</span>

    <span class="c1"># 선형 회귀 모델링을 통해 얻은 coefficient, intercept 입니다.</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;coefficient=</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">coef_</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;intercept=</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">intercept_</span><span class="p">))</span>

    <span class="c1"># 평가: 테스트 데이터에 대해서 Accuracy 값을 구합니다.</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">np_test_ys</span><span class="p">,</span> <span class="n">np_pred_ys</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;acc=</span><span class="si">{:.5f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc</span><span class="p">))</span>

    <span class="n">cr</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">classification_report</span><span class="p">(</span><span class="n">np_test_ys</span><span class="p">,</span> <span class="n">np_pred_ys</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;classification_report</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">cr</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>data shape: np_data_xs=(100000, 10), np_data_ys=(100000,)
train shape: np_train_xs=(70000, 10), np_train_ys=(70000,)
test shape: np_test_xs=(30000, 10), np_test_ys=(30000,)
model=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,
       l1_ratio=0.15, learning_rate=&#39;optimal&#39;, loss=&#39;hinge&#39;, max_iter=None,
       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty=&#39;l2&#39;,
       power_t=0.5, random_state=None, shuffle=True, tol=None,
       validation_fraction=0.1, verbose=0, warm_start=False)
coefficient=[[ 0.86574911 -0.35596145 -0.20190227  0.1375304   0.45958955  0.06000423
  -0.06038292  0.26419997 -0.2317192  -0.17356518]
 [-1.19738988 -0.14076485  0.96455876  0.07127453  0.00822414  0.06779517
   0.11478303 -0.16507975 -0.10597724 -0.25717476]
 [ 0.28599846  0.20450951 -0.95752513  0.0636483  -0.68330475 -0.05369482
  -0.14439814 -0.15918971  0.2032468   0.60044455]]
intercept=[-1.12265416 -1.34042843 -1.26664501]
acc=0.78687
classification_report
               precision    recall  f1-score   support

           0       0.81      0.67      0.73     10004
           1       0.68      0.82      0.74     10004
           2       0.90      0.87      0.88      9992

   micro avg       0.79      0.79      0.79     30000
   macro avg       0.80      0.79      0.79     30000
weighted avg       0.80      0.79      0.79     30000

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
 

