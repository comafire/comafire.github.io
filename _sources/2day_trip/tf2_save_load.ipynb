{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Save/Load (TF2)\n",
    "\n",
    "https://www.tensorflow.org/tutorials/keras/save_and_load?hl=ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설치\n",
    "!pip install -q --upgrade pip\n",
    "!pip install -q pyyaml h5py  # HDF5 포맷으로 모델을 저장하기 위해서 필요합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python ver=3.7.6 (default, Nov 21 2020, 22:51:13) \n",
      "[Clang 12.0.0 (clang-1200.0.32.27)]\n",
      "pandas ver=1.0.5\n",
      "numpy ver=1.19.5\n",
      "tensorflow ver=2.4.1\n",
      "tensorflow execuring eagerly=True\n",
      "tensorflow hub ver=0.11.0\n",
      "tensorflow GPU=False\n",
      "senborn ver=0.10.0\n"
     ]
    }
   ],
   "source": [
    "# 경고 메시지 출력 끄기\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "# 노트북 셀 표시를 브라우저 전체 폭 사용하기\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys, shutil\n",
    "\n",
    "rseed = 22\n",
    "import random\n",
    "random.seed(rseed)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(rseed)\n",
    "np.set_printoptions(precision=5)\n",
    "np.set_printoptions(formatter={'float_kind': \"{:.5f}\".format})\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None) \n",
    "pd.set_option('display.max_columns', None) \n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.display.float_format = '{:,.5f}'.format\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(rseed)\n",
    "tf.keras.backend.set_floatx('float32') # keras default float type 설정\n",
    "\n",
    "import tensorflow_hub as tfhub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "print(f\"python ver={sys.version}\")\n",
    "print(f\"pandas ver={pd.__version__}\")\n",
    "print(f\"numpy ver={np.__version__}\")\n",
    "print(f\"tensorflow ver={tf.__version__}\")\n",
    "print(f\"tensorflow execuring eagerly={tf.executing_eagerly()}\")\n",
    "print(f\"tensorflow hub ver={tfhub.__version__}\")\n",
    "print(f\"tensorflow GPU={'True' if tf.config.experimental.list_physical_devices('GPU') else 'False'}\")\n",
    "print(f\"senborn ver={sns.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 저장 방식\n",
    "\n",
    "사용하는 API에 따라서 여러가지 방법으로 텐서플로 모델을 저장할 수 있습니다. 이 문서는 텐서플로 모델을 만들고 훈련하기 위한 고수준 API인 tf.keras를 사용합니다. 다른 방법들에 대해서는 텐서플로의 [저장과 복원 문서](https://www.tensorflow.org/guide/saved_model?hl=ko)와 [즉시 실행(eager execution) 문서의 저장하기 섹션](https://www.tensorflow.org/guide/eager?hl=ko#object-based_saving)을 참고하세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 데이터셋 받기\n",
    "\n",
    "MNIST 데이터셋으로 모델을 훈련하여 가중치를 저장하는 예제를 만들어 보겠습니다. 모델 실행 속도를 빠르게 하기 위해 샘플에서 처음 1,000개만 사용겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels[:1000]\n",
    "test_labels = test_labels[:1000]\n",
    "\n",
    "train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 간단한 Sequential 모델을 정의합니다\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', \n",
    "                  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 모델 객체를 만듭니다\n",
    "model = create_model()\n",
    "\n",
    "# 모델 구조를 출력합니다\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련하는 동안 체크포인트 저장하기\n",
    "\n",
    "훈련 중간과 훈련 마지막에 체크포인트(checkpoint)를 자동으로 저장하도록 하는 것이 많이 사용하는 방법입니다. 다시 훈련하지 않고 모델을 재사용하거나 훈련 과정이 중지된 경우 이어서 훈련을 진행할 수 있습니다. tf.keras.callbacks.ModelCheckpoint은 이런 작업을 수행하는 콜백(callback)입니다. 이 콜백은 체크포인트 작업을 조정할 수 있도록 여러가지 매개변수를 제공합니다.\n",
    "\n",
    "### 체크포인트 콜백 사용하기\n",
    "\n",
    "훈련하는 동안 가중치를 저장하기 위해 ModelCheckpoint 콜백을 만들어 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_dir: /tmp/training_1\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 1s 30ms/step - loss: 1.6218 - accuracy: 0.4786 - val_loss: 0.7245 - val_accuracy: 0.7790\n",
      "\n",
      "Epoch 00001: saving model to /tmp/training_1/cp.ckpt\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.8811 - val_loss: 0.5206 - val_accuracy: 0.8440\n",
      "\n",
      "Epoch 00002: saving model to /tmp/training_1/cp.ckpt\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2807 - accuracy: 0.9353 - val_loss: 0.4686 - val_accuracy: 0.8540\n",
      "\n",
      "Epoch 00003: saving model to /tmp/training_1/cp.ckpt\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2214 - accuracy: 0.9441 - val_loss: 0.4320 - val_accuracy: 0.8660\n",
      "\n",
      "Epoch 00004: saving model to /tmp/training_1/cp.ckpt\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1763 - accuracy: 0.9547 - val_loss: 0.4132 - val_accuracy: 0.8650\n",
      "\n",
      "Epoch 00005: saving model to /tmp/training_1/cp.ckpt\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1072 - accuracy: 0.9854 - val_loss: 0.4154 - val_accuracy: 0.8650\n",
      "\n",
      "Epoch 00006: saving model to /tmp/training_1/cp.ckpt\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0949 - accuracy: 0.9823 - val_loss: 0.3963 - val_accuracy: 0.8710\n",
      "\n",
      "Epoch 00007: saving model to /tmp/training_1/cp.ckpt\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.9947 - val_loss: 0.4074 - val_accuracy: 0.8670\n",
      "\n",
      "Epoch 00008: saving model to /tmp/training_1/cp.ckpt\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.0517 - accuracy: 0.9930 - val_loss: 0.3865 - val_accuracy: 0.8720\n",
      "\n",
      "Epoch 00009: saving model to /tmp/training_1/cp.ckpt\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.9977 - val_loss: 0.4083 - val_accuracy: 0.8720\n",
      "\n",
      "Epoch 00010: saving model to /tmp/training_1/cp.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x196868850>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"/tmp/training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "print(f\"checkpoint_dir: {checkpoint_dir}\")\n",
    "if os.path.exists(checkpoint_dir) and os.path.isdir(checkpoint_dir):\n",
    "    shutil.rmtree(checkpoint_dir)\n",
    "\n",
    "# 모델의 가중치를 저장하는 콜백 만들기\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True, verbose=1)\n",
    "\n",
    "# 새로운 콜백으로 모델 훈련하기\n",
    "model.fit(train_images, train_labels, epochs=10,\n",
    "          validation_data=(test_images,test_labels), callbacks=[cp_callback])  # 콜백을 훈련에 전달합니다\n",
    "\n",
    "# 옵티마이저의 상태를 저장하는 것과 관련되어 경고가 발생할 수 있습니다.\n",
    "# 이 경고는 (그리고 이 노트북의 다른 비슷한 경고는) 이전 사용 방식을 권장하지 않기 위함이며 무시해도 좋습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 코드는 텐서플로 체크포인트 파일을 만들고 에포크가 종료될 때마다 업데이트합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH=/tmp/training_1\n",
      "total 9568\n",
      "drwxr-xr-x   5 comafire  wheel      160  3  7 00:06 \u001b[34m.\u001b[m\u001b[m\n",
      "drwxrwxrwt  17 root      wheel      544  3  7 00:06 \u001b[30m\u001b[42m..\u001b[m\u001b[m\n",
      "-rw-r--r--   1 comafire  wheel       71  3  7 00:06 checkpoint\n",
      "-rw-r--r--   1 comafire  wheel  4886673  3  7 00:06 cp.ckpt.data-00000-of-00001\n",
      "-rw-r--r--   1 comafire  wheel     1222  3  7 00:06 cp.ckpt.index\n"
     ]
    }
   ],
   "source": [
    "!echo \"PATH={checkpoint_dir}\"\n",
    "!ls -al {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련하지 않은 새로운 모델을 만들어 보겠습니다. 가중치만 복원할 땐 원본 모델과 동일한 구조로 모델을 만들어야 합니다. 여기서는 동일한 구조로 모델을 만들었으므로 다른 객체이지만 가중치를 공유할 수 있습니다.\n",
    "\n",
    "훈련하지 않은 새 모델을 만들고 테스트 세트에서 평가해 보죠. 훈련되지 않은 모델의 성능은 무작위로 선택하는 정도의 수준입니다(~10% 정확도):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 2.3566 - accuracy: 0.1520\n",
      "훈련되지 않은 모델의 정확도: 15.20%\n"
     ]
    }
   ],
   "source": [
    "# 기본 모델 객체를 만듭니다\n",
    "model = create_model()\n",
    "\n",
    "# 모델을 평가합니다\n",
    "loss, acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"훈련되지 않은 모델의 정확도: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "체크포인트에서 가중치를 로드하고 다시 평가해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4083 - accuracy: 0.8720\n",
      "복원된 모델의 정확도: 87.20%\n"
     ]
    }
   ],
   "source": [
    "# 가중치 로드\n",
    "model.load_weights(checkpoint_path)\n",
    "\n",
    "# 모델 재평가\n",
    "loss,acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"복원된 모델의 정확도: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 체크포인트 콜백 매개변수\n",
    "\n",
    "체크포인트 이름을 고유하게 만들어 저장할 수 있습니다. 에포크 횟수가 많아지면 저장되는 모델이 많아지기 때문에 이전 에포크보다 향상될때만 저장해 봅니다. \n",
    "\n",
    "새로운 모델을 훈련하고 에포크마다 고유한 이름으로 Best 체크포인트만을 저장해 보겠습니다: (기존 예제에서 사용되었던 period 파라미터는 deprecated 됨) \n",
    "\n",
    "(노트: 텐서플로는 따로 설정하지 않는다면 기본적으로 최근 5개의 체크포인트만 저장합니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_dir: /tmp/training_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.73039, saving model to /tmp/training_2/cp-0001.ckpt\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.73039 to 0.53101, saving model to /tmp/training_2/cp-0002.ckpt\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.53101 to 0.46557, saving model to /tmp/training_2/cp-0003.ckpt\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.46557 to 0.42657, saving model to /tmp/training_2/cp-0004.ckpt\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.42657 to 0.41130, saving model to /tmp/training_2/cp-0005.ckpt\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.41130\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.41130 to 0.37906, saving model to /tmp/training_2/cp-0007.ckpt\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.37906\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.37906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1972eb050>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일 이름에 에포크 번호를 포함시킵니다(`str.format` 포맷)\n",
    "checkpoint_path = \"/tmp/training_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "print(f\"checkpoint_dir: {checkpoint_dir}\")\n",
    "if os.path.exists(checkpoint_dir) and os.path.isdir(checkpoint_dir):\n",
    "    shutil.rmtree(checkpoint_dir)\n",
    "    \n",
    "# 에포크마다 Best 가중치를 저장하기 위한 콜백을 만듭니다\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, verbose=1, \n",
    "                                                 save_weights_only=True, save_best_only=True) \n",
    "\n",
    "# 새로운 모델 객체를 만듭니다\n",
    "model = create_model()\n",
    "\n",
    "# `checkpoint_path` 포맷을 사용하는 가중치를 저장합니다\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "# 새로운 콜백을 사용하여 모델을 훈련합니다\n",
    "model.fit(train_images, train_labels, epochs=50, \n",
    "          callbacks=[cp_callback], validation_data=(test_images,test_labels), verbose=0)\n",
    "\n",
    "# 옵티마이저의 상태를 저장하는 것과 관련되어 경고가 발생할 수 있습니다.\n",
    "# 이 경고는 (그리고 이 노트북의 다른 비슷한 경고는) 이전 사용 방식을 권장하지 않기 위함이며 무시해도 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH=/tmp/training_2\n",
      "total 60560\n",
      "drwxr-xr-x  17 comafire  wheel      544  3  7 00:06 \u001b[34m.\u001b[m\u001b[m\n",
      "drwxrwxrwt  17 root      wheel      544  3  7 00:06 \u001b[30m\u001b[42m..\u001b[m\u001b[m\n",
      "-rw-r--r--   1 comafire  wheel       81  3  7 00:06 checkpoint\n",
      "-rw-r--r--   1 comafire  wheel  1628726  3  7 00:06 cp-0000.ckpt.data-00000-of-00001\n",
      "-rw-r--r--   1 comafire  wheel      402  3  7 00:06 cp-0000.ckpt.index\n",
      "-rw-r--r--   1 comafire  wheel  4886685  3  7 00:06 cp-0001.ckpt.data-00000-of-00001\n",
      "-rw-r--r--   1 comafire  wheel     1222  3  7 00:06 cp-0001.ckpt.index\n",
      "-rw-r--r--   1 comafire  wheel  4886685  3  7 00:06 cp-0002.ckpt.data-00000-of-00001\n",
      "-rw-r--r--   1 comafire  wheel     1222  3  7 00:06 cp-0002.ckpt.index\n",
      "-rw-r--r--   1 comafire  wheel  4886685  3  7 00:06 cp-0003.ckpt.data-00000-of-00001\n",
      "-rw-r--r--   1 comafire  wheel     1222  3  7 00:06 cp-0003.ckpt.index\n",
      "-rw-r--r--   1 comafire  wheel  4886685  3  7 00:06 cp-0004.ckpt.data-00000-of-00001\n",
      "-rw-r--r--   1 comafire  wheel     1222  3  7 00:06 cp-0004.ckpt.index\n",
      "-rw-r--r--   1 comafire  wheel  4886685  3  7 00:06 cp-0005.ckpt.data-00000-of-00001\n",
      "-rw-r--r--   1 comafire  wheel     1222  3  7 00:06 cp-0005.ckpt.index\n",
      "-rw-r--r--   1 comafire  wheel  4886685  3  7 00:06 cp-0007.ckpt.data-00000-of-00001\n",
      "-rw-r--r--   1 comafire  wheel     1222  3  7 00:06 cp-0007.ckpt.index\n"
     ]
    }
   ],
   "source": [
    "!echo \"PATH={checkpoint_dir}\"\n",
    "!ls -al {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/training_2/cp-0007.ckpt'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 초기화하고 최근 체크포인트를 로드하여 테스트해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.3791 - accuracy: 0.8740\n",
      "복원된 모델의 정확도: 87.40%\n"
     ]
    }
   ],
   "source": [
    "# 새로운 모델 객체를 만듭니다\n",
    "model = create_model()\n",
    "\n",
    "# 이전에 저장한 가중치를 로드합니다\n",
    "model.load_weights(latest)\n",
    "\n",
    "# 모델을 재평가합니다\n",
    "loss, acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"복원된 모델의 정확도: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수동으로 가중치 저장하기\n",
    "\n",
    "앞에서 가중치를 모델에 로드하는 방법을 보았습니다. 수동으로 가중치를 저장하는 것도 쉽습니다. [Model.save_weights 메서드](https://www.tensorflow.org/api_docs/python/tf/keras/Model?hl=ko#save_weights)를 사용합니다. tf.keras는, 특히 save_weights는 .ckpt 확장자를 가진 텐서플로 [체크포인트](https://www.tensorflow.org/guide/checkpoint?hl=ko) 포맷을 사용합니다(.h5 확장자의 HDF5으로 저장하는 것은 [Save and serialize models 가이드](https://www.tensorflow.org/guide/keras/save_and_serialize?hl=ko#weights_only_saving_in_savedmodel_format)에서 다룹니다):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_dir=/tmp/checkpoints\n",
      "my_checkpoint=/tmp/checkpoints/my_checkpoint\n",
      "32/32 - 0s - loss: 0.3791 - accuracy: 0.8740\n",
      "복원된 모델의 정확도: 87.40%\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = \"/tmp/checkpoints\"\n",
    "print(f\"checkpoint_dir={checkpoint_dir}\")\n",
    "if os.path.exists(checkpoint_dir) and os.path.isdir(checkpoint_dir):\n",
    "    shutil.rmtree(checkpoint_dir)\n",
    "\n",
    "# 가중치를 저장합니다  \n",
    "my_checkpoint = os.path.join(checkpoint_dir, 'my_checkpoint')\n",
    "print(f\"my_checkpoint={my_checkpoint}\")\n",
    "model.save_weights(my_checkpoint)\n",
    "\n",
    "# 새로운 모델 객체를 만듭니다\n",
    "model = create_model()\n",
    "\n",
    "# 가중치를 복원합니다\n",
    "model.load_weights(my_checkpoint)\n",
    "\n",
    "# 모델을 평가합니다\n",
    "loss,acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"복원된 모델의 정확도: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 모델 저장하기\n",
    "\n",
    "[model.save 메서드](https://www.tensorflow.org/api_docs/python/tf/keras/Model?hl=ko#save)를 호출하여 모델의 구조, 가중치, 훈련 설정을 하나의 파일/폴더에 저장합니다. 모델을 저장하기 때문에 원본 파이썬 코드*가 없어도 사용할 수 있습니다. 옵티마이저 상태가 복원되므로 정확히 중지한 시점에서 다시 훈련을 시작할 수 있습니다.\n",
    "\n",
    "두 개의 포맷(Saved Model, HDF5)으로 모델을 저장할 수 있습니다. 텐서플로의 SavedModel 포맷은 TF2.x에서기본 파일 포맷입니다. 하지만 HDF5 포맷으로 저장할 수도 있습니다. 두 파일 포맷으로 전체 모델을 저장하는 방법은 아래에서 자세히 설명합니다.\n",
    "\n",
    "전체 모델을 저장하는 기능은 매우 유용합니다. TensorFlow.js로 모델을 로드한 다음 웹 브라우저에서 모델을 훈련하고 실행할 수 있습니다([SavedModel](https://js.tensorflow.org/tutorials/import-saved-model.html?hl=ko)과 [HDF5](https://js.tensorflow.org/tutorials/import-keras.html?hl=ko)). 또는 모바일 장치에 맞도록 변환한 다음 TensorFlow Lite를 사용하여 실행할 수 있습니다([Saved Model](https://www.tensorflow.org/lite/convert/python_api?hl=ko#exporting_a_savedmodel_), [HDF5](https://www.tensorflow.org/lite/convert/python_api?hl=ko#exporting_a_tfkeras_file_)).\n",
    "\n",
    "* 사용자 정의 객체(예를 들면 상속으로 만든 클래스나 층)는 저장하고 로드하는데 특별한 주의가 필요합니다. 아래 사용자 정의 객체 저장하기 섹션을 참고하세요.\n",
    "\n",
    "### SavedModel 포맷\n",
    "\n",
    "SavedModel 포맷은 모델을 직렬화하는 다른 방법입니다. 이 포맷으로 저장한 모델은 tf.keras.models.load_model로 복원할 수 있고 텐서플로 서빙과 호환됩니다. [SavedModel 가이드](https://www.tensorflow.org/guide/saved_model?hl=ko)에서 SavedModel를 서빙하고 점검하는 자세한 방법을 제공합니다. 이 섹션에서는 모델을 저장하고 복원하는 방법을 안내하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_dir: /tmp/models\n",
      "saved_model=/tmp/models/saved_model\n",
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.6786 - accuracy: 0.4645\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.8595\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2819 - accuracy: 0.9307\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2264 - accuracy: 0.9478\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.9641\n",
      "my_model=/tmp/models/saved_model/my_model\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "INFO:tensorflow:Assets written to: /tmp/models/saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/tmp/models\"\n",
    "print(f\"model_dir: {model_dir}\")\n",
    "if os.path.exists(model_dir) and os.path.isdir(model_dir):\n",
    "    shutil.rmtree(model_dir)\n",
    "\n",
    "saved_model = os.path.join(model_dir, 'saved_model')\n",
    "print(f\"saved_model={saved_model}\")\n",
    "\n",
    "# 새로운 모델 객체를 만들고 훈련합니다\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# SavedModel로 전체 모델을 저장합니다\n",
    "my_model = os.path.join(saved_model, 'my_model')\n",
    "print(f\"my_model={my_model}\")\n",
    "model.save(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SavedModel 포맷은 프로토콜 버퍼 이진 파일과 텐서플로 체크포인트를 담고 있는 디렉토리입니다. 저장된 모델의 디렉토리를 확인해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n",
      "drwxr-xr-x  3 comafire  wheel  96  3  7 00:06 \u001b[34msaved_model\u001b[m\u001b[m\n",
      "\n",
      "/tmp/models/saved_model:\n",
      "total 0\n",
      "drwxr-xr-x  5 comafire  wheel  160  3  7 00:06 \u001b[34mmy_model\u001b[m\u001b[m\n",
      "\n",
      "/tmp/models/saved_model/my_model:\n",
      "total 168\n",
      "drwxr-xr-x  2 comafire  wheel     64  3  7 00:06 \u001b[34massets\u001b[m\u001b[m\n",
      "-rw-r--r--  1 comafire  wheel  82620  3  7 00:06 saved_model.pb\n",
      "drwxr-xr-x  4 comafire  wheel    128  3  7 00:06 \u001b[34mvariables\u001b[m\u001b[m\n",
      "\n",
      "/tmp/models/saved_model/my_model/assets:\n",
      "\n",
      "/tmp/models/saved_model/my_model/variables:\n",
      "total 9560\n",
      "-rw-r--r--  1 comafire  wheel  4888491  3  7 00:06 variables.data-00000-of-00001\n",
      "-rw-r--r--  1 comafire  wheel     1463  3  7 00:06 variables.index\n"
     ]
    }
   ],
   "source": [
    "# my_model 디렉토리:  assests 폴더, saved_model.pb, variables 폴더\n",
    "!ls -lR {model_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저장된 모델로부터 새로운 케라스 모델을 로드합니다:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model(my_model)\n",
    "\n",
    "# 모델 구조를 확인합니다\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "복원된 모델은 원본 모델과 동일한 매개변수로 컴파일되어 있습니다. 이 모델을 평가하고 예측에 사용해 보죠:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4118 - accuracy: 0.8690\n",
      "복원된 모델의 정확도: 86.90%\n",
      "(1000, 10)\n"
     ]
    }
   ],
   "source": [
    "# 복원된 모델을 평가합니다\n",
    "loss, acc = new_model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('복원된 모델의 정확도: {:5.2f}%'.format(100*acc))\n",
    "\n",
    "print(new_model.predict(test_images).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 파일로 저장하기\n",
    "\n",
    "케라스는 HDF5 표준을 따르는 기본 저장 포맷을 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_dir: /tmp/models\n",
      "Epoch 1/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 1.5733 - accuracy: 0.5103\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.8640\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.9265\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.9426\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.1709 - accuracy: 0.9651\n",
      "my_model=/tmp/models/my_model.h5\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/tmp/models\"\n",
    "print(f\"model_dir: {model_dir}\")\n",
    "if os.path.exists(model_dir) and os.path.isdir(model_dir):\n",
    "    shutil.rmtree(model_dir)\n",
    "    \n",
    "# 새로운 모델 객체를 만들고 훈련합니다\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# 전체 모델을 HDF5 파일로 저장합니다\n",
    "# '.h5' 확장자는 이 모델이 HDF5로 저장되었다는 것을 나타냅니다\n",
    "my_model = os.path.join(model_dir, 'my_model.h5')\n",
    "print(f\"my_model={my_model}\")\n",
    "model.save(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 이 파일로부터 모델을 다시 만들어 보죠:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 가중치와 옵티마이저를 포함하여 정확히 동일한 모델을 다시 생성합니다\n",
    "new_model = tf.keras.models.load_model(my_model)\n",
    "\n",
    "# 모델 구조를 출력합니다\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도를 확인해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 0s - loss: 0.4237 - accuracy: 0.8690\n",
      "복원된 모델의 정확도: 86.90%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print('복원된 모델의 정확도: {:5.2f}%'.format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스는 모델 구조를 파악하여 저장합니다. 이 방식은 다음과 같은 모든 것을 저장합니다:\n",
    "\n",
    "* 가중치 값\n",
    "* 모델 구조\n",
    "* 모델의 훈련 설정(컴파일할 때 전달한 값)\n",
    "* 옵티마이저와 필요하면 옵티마이저 상태(중지된 지점부터 다시 시작할 수 있습니다)\n",
    "\n",
    "체크포인트가 호환되지 않기 때문에 케라스는 v1.x 옵티마이저(tf.compat.v1.train)를 저장할 수 없습니다. v1.x 옵티마이저를 사용하려면 로드한 후에 모델을 다시 컴파일해야 합니다. 따라서 옵티마이저의 상태를 잃게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자 정의 객체\n",
    "\n",
    "SaveModel 포맷을 사용한다면 이 섹션은 건너 뛰어도 됩니다. HDF5와 SavedModel 사이의 주요 차이점은 HDF5가 객체로 모델 구조를 저장하고 SavedModel은 실행 그래프로 저장하는 것입니다. 따라서 SavedModel은 원본 코드 없이 상속 모델과 사용자 정의 층 같은 사용자 정의 객체를 저장할 수 있습니다.\n",
    "\n",
    "사용자 정의 객체를 HDF5로 저장하려면 다음 과정을 따르세요:\n",
    "\n",
    "* 이 객체에 get_config 메서드를 정의하고 선택적으로 from_config 클래스 메서드를 정의합니다.\n",
    " * get_config(self)는 객체를 다시 생성하기 위해 필요한 JSON 직렬화된 매개변수 딕셔너리를 반환합니다.\n",
    " * from_config(cls, config)는 get_config에서 반환된 설정을 사용해 새로운 객체를 만듭니다. 기본적으로 이 함수는 이 설정을 초기화 메서드의 매개변수로 사용합니다(return cls(**config)).\n",
    "* 모델을 로드할 때 이 객체를 custom_objects 매개변수로 전달합니다. 문자열 클래스 이름과 파이썬 클래스를 매핑한 딕서너리를 매개변수로 제공해야 합니다. 예를 들면 tf.keras.models.load_model(path, custom_objects={'CustomLayer': CustomLayer})\n",
    "\n",
    "사용자 정의 객체와 get_config에 관한 예제를 보려면 [Writing layers and models from scratch 튜토리얼](https://www.tensorflow.org/guide/keras/custom_layers_and_models?hl=ko)을 참고하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIT License\n",
    "#\n",
    "# Copyright (c) 2017 François Chollet\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a\n",
    "# copy of this software and associated documentation files (the \"Software\"),\n",
    "# to deal in the Software without restriction, including without limitation\n",
    "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
    "# and/or sell copies of the Software, and to permit persons to whom the\n",
    "# Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
    "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
    "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
    "# DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nikola": {
   "category": "",
   "date": "2019-03-09",
   "description": "",
   "link": "",
   "slug": "ml-keras-10mins",
   "tags": "",
   "title": "Machine Learning - Keras 10분만에 훑어보기",
   "type": "text"
  },
  "notebookId": 2469278771832403,
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
