{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced Class\n",
    "\n",
    "데이터 준비 과정인 EDA(Exploratory Data Analysis) 에서 분석에 맞는 데이터를 만들기 위해 많은 기법들을 통해 데이터를 정제합니다. 지도 학습을 통해 Classification 을 위한 데이터 준비 과정에서 일반적으로 발생하는 문제 중에 하나는 예측하고자 하는 Class 에 해당하는 데이터 수의 불균형을 들 수 있습니다.\n",
    "\n",
    "예를 들어 공장에서 불량품을 분류하는 문제에 대한 모델을 만들 경우, 불량율이 1% 라고 한다면 양품과 불량품 Class 내의 데이터 비율은 99:1 로 불균형을 이루게 됩니다. 이는 모델 학습 및 평가에 많은 영향을 주게 됩니다. 모델이 학습 후 모든 예측을 양품으로 하더라도 단순히 정확도는 99% 가 되기 때문입니다. 물론 이 부분을 평가하는 다른 함수들이 존재하긴 하지만, 학습을 통해 좋은 모델을 얻기 위해서라도 Class내의 데이터 불균형 문제는 해결하는 것이 좋습니다.\n",
    "\n",
    "Package: https://imbalanced-learn.readthedocs.io/en/stable/index.html\n",
    "\n",
    "\n",
    "## Over-sampling & Under-sampling\n",
    "\n",
    "Over-sampling 은 Class 내의 데이터 비율이 낮은 데이터를 여러 방법으로 샘플링하여 높은쪽 비율로 맞추는 방법이고, Under-sampling 은 Class 내의 데이터 비율이 높은 데이터를 여러 방법으로 샘플링하여 낮은쪽 비율로 맞추는 방법입니다. \n",
    "\n",
    "![Over-sampling Under-sampling](https://github.com/wmlba/innovate2019/raw/6a012a1e310f16ee1811cd7d316d11f247b8f6a7/resampling.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over-sampling\n",
    "\n",
    "Class 내의 데이터 비율이 [0.01, 0.05, 0.94] 인 가상의 데이터를 만들고, 불균형 데이터를 통해 SVM 모델을 학습하여 평가한 결과와 Over-sampling 을 통해 균형 데이터로 만들고 학습한 결과입니다.\n",
    "\n",
    "* Random Sampling (RandomOverSampler)\n",
    "* The Synthetic Minority Oversampling Technique (SMOTE) [CBHK2002](https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html#cbhk2002)\n",
    "* The Adaptive Synthetic (ADASYN) [HBGL2008](https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html#hbgl2008)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_data_ys=[(0, 132), (1, 523), (2, 9345)]\n",
      "np_train_ys=[(0, 89), (1, 380), (2, 6531)]\n",
      "np_test_ys=[(0, 43), (1, 143), (2, 2814)]\n",
      "classification_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        43\n",
      "           1       0.73      0.66      0.69       143\n",
      "           2       0.98      1.00      0.99      2814\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3000\n",
      "   macro avg       0.57      0.55      0.56      3000\n",
      "weighted avg       0.95      0.97      0.96      3000\n",
      "\n",
      "np_train_resampled_ys=[(0, 6531), (1, 6531), (2, 6531)]\n",
      "np_test_ys=[(0, 43), (1, 143), (2, 2814)]\n",
      "classification_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.63      0.53        43\n",
      "           1       0.34      0.62      0.44       143\n",
      "           2       0.99      0.94      0.96      2814\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      3000\n",
      "   macro avg       0.60      0.73      0.65      3000\n",
      "weighted avg       0.95      0.92      0.93      3000\n",
      "\n",
      "np_train_resampled_ys=[(0, 6531), (1, 6531), (2, 6531)]\n",
      "np_test_ys=[(0, 43), (1, 143), (2, 2814)]\n",
      "classification_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.63      0.53        43\n",
      "           1       0.36      0.66      0.47       143\n",
      "           2       0.99      0.94      0.96      2814\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      3000\n",
      "   macro avg       0.60      0.74      0.65      3000\n",
      "weighted avg       0.95      0.92      0.93      3000\n",
      "\n",
      "np_train_resampled_ys=[(0, 6529), (1, 6527), (2, 6531)]\n",
      "np_test_ys=[(0, 43), (1, 143), (2, 2814)]\n",
      "classification_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.79      0.44        43\n",
      "           1       0.08      0.41      0.14       143\n",
      "           2       0.99      0.78      0.87      2814\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      3000\n",
      "   macro avg       0.46      0.66      0.48      3000\n",
      "weighted avg       0.94      0.76      0.83      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets, svm, metrics\n",
    "from imblearn import over_sampling\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터\n",
    "n_samples = 10000\n",
    "np_data_xs, np_data_ys = datasets.make_classification(n_samples=n_samples, \n",
    "                                                      n_features=2, n_informative=2,\n",
    "                                                      n_redundant=0, n_repeated=0, \n",
    "                                                      n_classes=3, n_clusters_per_class=1,\n",
    "                                                      weights=[0.01, 0.05, 0.94],\n",
    "                                                      class_sep=0.8, random_state=0)\n",
    "print(\"np_data_ys={}\".format(sorted(Counter(np_data_ys).items())))\n",
    "idx = int(n_samples * 0.7)\n",
    "np_train_xs = np_data_xs[:idx]\n",
    "np_train_ys = np_data_ys[:idx]\n",
    "np_test_xs = np_data_xs[idx:]\n",
    "np_test_ys = np_data_ys[idx:]\n",
    "print(\"np_train_ys={}\".format(sorted(Counter(np_train_ys).items())))\n",
    "print(\"np_test_ys={}\".format(sorted(Counter(np_test_ys).items())))\n",
    "\n",
    "# 불균형 데이터 학습\n",
    "model = svm.LinearSVC()\n",
    "model.fit(np_train_xs, np_train_ys) \n",
    "\n",
    "# 평가\n",
    "np_pred_ys = model.predict(np_test_xs)\n",
    "cr = metrics.classification_report(np_test_ys, np_pred_ys)\n",
    "print(\"classification_report\\n\", cr)\n",
    "\n",
    "# Over-sampling\n",
    "samplers = [\n",
    "    over_sampling.RandomOverSampler(random_state=0),\n",
    "    over_sampling.SMOTE(random_state=0),\n",
    "    over_sampling.ADASYN(random_state=0)\n",
    "]\n",
    "\n",
    "for sampler in samplers:\n",
    "    np_train_resampled_xs, np_train_resampled_ys = sampler.fit_resample(np_train_xs, np_train_ys)\n",
    "\n",
    "    print(\"np_train_resampled_ys={}\".format(sorted(Counter(np_train_resampled_ys).items())))\n",
    "    print(\"np_test_ys={}\".format(sorted(Counter(np_test_ys).items())))\n",
    "\n",
    "    # 균형 데이터 학습\n",
    "    model = svm.LinearSVC()\n",
    "    model.fit(np_train_resampled_xs, np_train_resampled_ys) \n",
    "\n",
    "    # 평가\n",
    "    np_pred_ys = model.predict(np_test_xs)\n",
    "    cr = metrics.classification_report(np_test_ys, np_pred_ys)\n",
    "    print(\"classification_report\\n\", cr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단순히 정확도 면에서는 불균형 데이터가 더 정확하다고 나오지만, Class 0 의 예측 성능은 매우 안좋게 나오게 됩니다. 모델의 균형적 측면에서 정확도는 조금 낮지만 균형 데이터로 학습한 모델이 더욱 안정적인 성능을 나타냄을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under-sampling\n",
    "\n",
    "Class 내의 데이터 비율이 [0.01, 0.05, 0.94] 인 가상의 데이터를 만들고, 불균형 데이터를 통해 SVM 모델을 학습하여 평가한 결과와 Under-sampling 을 통해 균형 데이터로 만들고 학습한 결과입니다.\n",
    "\n",
    "* Random Sampling (RandomUnderSampler)\n",
    "* K-means 알고리즘을 이용하여 sampling(ClusterCentroids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_data_ys=[(0, 132), (1, 523), (2, 9345)]\n",
      "np_train_ys=[(0, 89), (1, 380), (2, 6531)]\n",
      "np_test_ys=[(0, 43), (1, 143), (2, 2814)]\n",
      "classification_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        43\n",
      "           1       0.73      0.66      0.69       143\n",
      "           2       0.98      1.00      0.99      2814\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3000\n",
      "   macro avg       0.57      0.55      0.56      3000\n",
      "weighted avg       0.95      0.97      0.96      3000\n",
      "\n",
      "np_train_resampled_ys=[(0, 89), (1, 89), (2, 89)]\n",
      "np_test_ys=[(0, 43), (1, 143), (2, 2814)]\n",
      "classification_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.63      0.43        43\n",
      "           1       0.52      0.64      0.57       143\n",
      "           2       0.99      0.96      0.97      2814\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      3000\n",
      "   macro avg       0.61      0.74      0.66      3000\n",
      "weighted avg       0.96      0.94      0.95      3000\n",
      "\n",
      "np_train_resampled_ys=[(0, 89), (1, 89), (2, 89)]\n",
      "np_test_ys=[(0, 43), (1, 143), (2, 2814)]\n",
      "classification_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.63      0.53        43\n",
      "           1       0.38      0.61      0.47       143\n",
      "           2       0.99      0.95      0.97      2814\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      3000\n",
      "   macro avg       0.61      0.73      0.66      3000\n",
      "weighted avg       0.95      0.93      0.94      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets, svm, metrics\n",
    "from imblearn import under_sampling\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터\n",
    "n_samples = 10000\n",
    "np_data_xs, np_data_ys = datasets.make_classification(n_samples=n_samples, \n",
    "                                                      n_features=2, n_informative=2,\n",
    "                                                      n_redundant=0, n_repeated=0, \n",
    "                                                      n_classes=3, n_clusters_per_class=1,\n",
    "                                                      weights=[0.01, 0.05, 0.94],\n",
    "                                                      class_sep=0.8, random_state=0)\n",
    "print(\"np_data_ys={}\".format(sorted(Counter(np_data_ys).items())))\n",
    "idx = int(n_samples * 0.7)\n",
    "np_train_xs = np_data_xs[:idx]\n",
    "np_train_ys = np_data_ys[:idx]\n",
    "np_test_xs = np_data_xs[idx:]\n",
    "np_test_ys = np_data_ys[idx:]\n",
    "print(\"np_train_ys={}\".format(sorted(Counter(np_train_ys).items())))\n",
    "print(\"np_test_ys={}\".format(sorted(Counter(np_test_ys).items())))\n",
    "\n",
    "# 불균형 데이터 학습\n",
    "model = svm.LinearSVC()\n",
    "model.fit(np_train_xs, np_train_ys) \n",
    "\n",
    "# 평가\n",
    "np_pred_ys = model.predict(np_test_xs)\n",
    "cr = metrics.classification_report(np_test_ys, np_pred_ys)\n",
    "print(\"classification_report\\n\", cr)\n",
    "\n",
    "# Under-sampling\n",
    "samplers = [\n",
    "    under_sampling.RandomUnderSampler(random_state=0),\n",
    "    under_sampling.ClusterCentroids(random_state=0)\n",
    "]\n",
    "\n",
    "for sampler in samplers:\n",
    "    np_train_resampled_xs, np_train_resampled_ys = sampler.fit_resample(np_train_xs, np_train_ys)\n",
    "\n",
    "    print(\"np_train_resampled_ys={}\".format(sorted(Counter(np_train_resampled_ys).items())))\n",
    "    print(\"np_test_ys={}\".format(sorted(Counter(np_test_ys).items())))\n",
    "\n",
    "    # 균형 데이터 학습\n",
    "    model = svm.LinearSVC()\n",
    "    model.fit(np_train_resampled_xs, np_train_resampled_ys) \n",
    "\n",
    "    # 평가\n",
    "    np_pred_ys = model.predict(np_test_xs)\n",
    "    cr = metrics.classification_report(np_test_ys, np_pred_ys)\n",
    "    print(\"classification_report\\n\", cr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단순히 정확도 면에서는 불균형 데이터가 더 정확하다고 나오지만, Class 0 의 예측 성능은 매우 안좋게 나오게 됩니다. 모델의 균형적 측면에서 정확도는 조금 낮지만 균형 데이터로 학습한 모델이 더욱 안정적인 성능을 나타냄을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nikola": {
   "category": "",
   "date": "2019-04-20",
   "description": "",
   "link": "",
   "slug": "ml-imbalanced-class",
   "tags": "",
   "title": "Machine Learning - Imbalanced Class",
   "type": "text"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
