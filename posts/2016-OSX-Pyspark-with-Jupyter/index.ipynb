{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark\n",
    "Spark 하면 먼저 클러스터를 떠올리게 되는데, 사실 로컬상에서 Spark을 이용해 프로그래밍을 하는 것도 복잡한 멀티프로세스, 멀티스레드 프로그래밍의 수고를 덜면서 로컬노드의 멀티 코어 자원을 손쉽게 활용할 수 있는 방법이기도 합니다.\n",
    "\n",
    "맥북에 Spark을 설치하고 Jupyter를 통해 Python을 이용하여 손쉽게 Spark을 사용해 봅시다.\n",
    "\n",
    "<!-- TEASER_END -->\n",
    "\n",
    "### Spark Install\n",
    "Java가 설치되어 있는지 확인합니다. 설치가 안되어 있다면 http://www.oracle.com/technetwork/java/javase/downloads/index.html 오라클 사이트에서 다운받아 설치합니다.\n",
    "\n",
    "```\n",
    "> which java\n",
    "/usr/bin/java\n",
    "> java -version\n",
    "java version \"1.8.0_91\"\n",
    "Java(TM) SE Runtime Environment (build 1.8.0_91-b14)\n",
    "Java HotSpot(TM) 64-Bit Server VM (build 25.91-b14, mixed mode)\n",
    "```\n",
    "\n",
    "Scala를 brew를 통해 설치합니다.\n",
    "\n",
    "```\n",
    "> brew install scala\n",
    "```\n",
    "\n",
    "Python 을 brew를 이용해 설치하고 의존성 패키지를 설치합니다.\n",
    "\n",
    "```\n",
    "> brew install python\n",
    "> sudo easy_install pip\n",
    "> sudo pip install py4j\n",
    "> sudo pip install ipython[all]\n",
    "> sudo pip install jupyter\n",
    "```\n",
    "\n",
    "https://spark.apache.org/downloads.html 사이트에서 원하는 버전의 Spark 을 다운로드 받습니다.\n",
    "\n",
    "로컬에 Spark을 설치하는 것은 간단히 Spark을 받아 압축을 푸는 것으로 끝납니다. 편의를 위해서 심볼릭 링크를 걸어둡니다.\n",
    "\n",
    "```\n",
    "> cd /usr/local\n",
    "> mv ~/Downloads/spark-2.0.0-bin-hadoop2.7.tgz ./\n",
    "> tar -zxvf spark-2.0.0-bin-hadoop2.7.tgz\n",
    "> ln -s spark-2.0.0-bin-hadoop2.7 spark\n",
    "```\n",
    "\n",
    "이제 쉘 환경설정파일에 환경변수를 설정합니다.\n",
    "\n",
    "```\n",
    "> vi ~/.bash_profile\n",
    "\n",
    "export PATH=\"/usr/local/sbin:$PATH\"\n",
    "\n",
    "export JAVA_HOME=$(/usr/libexec/java_home)\n",
    "export SCALA_HOME=/usr/local/bin/scala\n",
    "export PATH=$PATH:$SCALA_HOME/bin\n",
    "\n",
    "export SPARK_HOME=/usr/local/spark\n",
    "export PATH=$PATH:$SPARK_HOME/bin\n",
    "export PYTHONPATH=$SPARK_HOME/python/:$PYTHONPATH\n",
    "export PYTHONPATH=$SPARK_HOME/python/lib/py4j-0.10-src.zip:$PYTHONPATH\n",
    "\n",
    "export PYTHON=/usr/local/bin/python\n",
    "\n",
    "```\n",
    "\n",
    "py4j 라이브러리의 경우 설치한 spark 안에 라이브러리 버전을 확인하여 이름을 넣어주세요.\n",
    "\n",
    "이제 notebook 디렉토리로 사용할 디렉토리를 생성하고 해당 디렉토리내에서 notebook을 실행하시면 브라우저가 실행되면서 친숙한 화면을 보실수 있습니다.\n",
    "\n",
    "```\n",
    "> mkdir -p ~/Projects/notebooks\n",
    "> cd ~/Projects/notebooks\n",
    "> ipython notebook\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "nikola": {
   "category": "",
   "date": "2016-01-01 00:00:00 UTC+09:00",
   "description": "",
   "link": "",
   "slug": "2016-OSX-Pyspark-with-Jupyter",
   "tags": "",
   "title": "맥에서 Jupyter 노트북으로 PySpark 사용하기",
   "type": "text"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
