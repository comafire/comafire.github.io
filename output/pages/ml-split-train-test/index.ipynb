{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Valid/Test 데이터 셋 나누기\n",
    "\n",
    "머신러닝은 주어진 데이터 셋에서 독립변수와 종속변수의 상관관계를 잘 나타낼 수 있는 모델을 학습을 통해서 생성하는 작업입니다. 따라서, 데이터 셋은 머신러닝에서 매우 중요한 요소이며, \"Garbage In, Garbage Out\" 이라는 말로 대표되고 있습니다.\n",
    "\n",
    "머신러닝에서 학습을 위한 데이터 셋을 준비하는데 중요한 것은 \n",
    "\n",
    "* 준비한 전체 학습 데이터 셋이 모집단을 대표할 수 있어야 하며\n",
    "* 분리한 Train/Test 셋 사이에 데이터 오염이 없어야 하고\n",
    "* 분리된 Train/Test 셋 또한 모집단을 대표할 수 있어야 한다.\n",
    "\n",
    "입니다. 데이터 셋이 모집단을 대표할 수 있어야 한다는 가정은 큰 수 이상의 랜덤 샘플을 통해 해결이 가능하지만, 데이터의 도메인에 따라 무작정 랜덤 샘플을 할수 없는 경우에는 도메인에 맞는 샘플링 방법을 통해 데이터를 확보해야 합니다. (예를 들어 시계열 데이터의 경우는 데이터 오염을 없애기 위해 시간 범위로 학습 데이터를 분리합니다.) 정해진 Train과 Test를 나누는 비율을 없지만, 보통 7:3, 8:2 정도의 비율을 통해 학습 데이터를 분리합니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: np_data_xs=(10, 20), np_data_ys=(10,)\n",
      "train shape: np_train_xs=(7, 20), np_train_ys=(7,)\n",
      "test shape: np_test_xs=(3, 20), np_test_ys=(3,)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets, model_selection, linear_model, metrics\n",
    "\n",
    "# 데이터 생성\n",
    "np.random.seed(0)\n",
    "n_samples = 10\n",
    "np_data_xs, np_data_ys = datasets.make_classification(n_samples=n_samples)\n",
    "print(\"data shape: np_data_xs={}, np_data_ys={}\".format(np_data_xs.shape, np_data_ys.shape))\n",
    "\n",
    "# 8:2 비율로 랜덤 샘플하여 Train/Test 셋 분리\n",
    "np_train_xs, np_test_xs, np_train_ys, np_test_ys = model_selection.train_test_split(\n",
    "    np_data_xs, np_data_ys, \n",
    "    test_size=0.3, shuffle=True, random_state=2)\n",
    "print(\"train shape: np_train_xs={}, np_train_ys={}\".format(np_train_xs.shape, np_train_ys.shape))\n",
    "print(\"test shape: np_test_xs={}, np_test_ys={}\".format(np_test_xs.shape, np_test_ys.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting\n",
    "\n",
    "모델은 학습을 통해 Train 데이터 셋을 잘 설명할 수 있는 최적화를 하게 됩니다. 하지만, 과도한 최적화는 새로운 데이터에 대한 적응성을 떨어 트리게 되어, 모델이 실제 배포 된 후, 오히려 제대로 된 성능을 내지 못하게 됩니다.\n",
    "\n",
    "Underfit(과소적합) 상태는 모델이 데이터 셋을 잘 설명하지 못하는 상태이며, Overfit(과적합) 상태는 모델이 너무 학습 데이터에 최적화되어 새로운 데이터에 대한 적응성이 떨어지는 상태 입니다.\n",
    "\n",
    "![overfitting](https://cdn-images-1.medium.com/max/1600/1*tBErXYVvTw2jSUYK7thU2A.png)\n",
    "\n",
    "Underfit은 모델 변경, 파라미터 최적화, Regularization(정규화) 제약을 줄이는 방향으로 해결 가능하며, Overfit의 경우에는 Early Stop 정책을 통한 학습 제한 및 정규화 제약을 높이는 방향으로 해결 가능합니다.\n",
    "\n",
    "# Cross Validation(교차검증)\n",
    "\n",
    "머신러닝 학습 과정에서 과적합을 방지하기 위해 Train 셋을 다시 Train/Valid 셋을 나누고, Valid 셋을 이용하여 학습 중 평가를 진행 하면서 학습이 잘 진행되고 있는지, 그리고 과적합이 일어나지 않는지 체크하고 과적합 전에 일찍 학습을 종료하는 Early Stop 정책을 사용하는 경우가 많습니다. Train 셋이 충분하다면 Test 셋을 나누었던 비율과 비슷한 7:3, 8:2 비율로 나누어 진행하면 되지만, Train 셋이 충분하지 않을 경우, Valid 셋은 학습하는데 누락 될 수 밖에 없게됩니다.\n",
    "\n",
    "이런 문제를 방지하기 위해서, Valid 셋을 누락 시키지 않고, 학습하기 위한 여러 교차 검증 방법이 존재 합니다.\n",
    "\n",
    "## K-Fold\n",
    "\n",
    "K-fold 방법은 교차검증 방법 중에서 가장 일반적으로 사용되는 방법입니다. Train 셋을 K 개의 그룹으로 나누고 1개는 Valid 셋이 되고 나머지는 Train 셋으로 하여 모델을 반복 학습 시키는 방법입니다. Repeated K-fold 방식은 다른 랜덤 인덱스로 K-fold 를 반복하는 방법입니다. K-fold 방법은 그룹내 Class 의 균형에 대한 고려가 없이 나누는 방법이기 때문에 그룹안에 학습 데이터의 Class 가 불균형하게 들어갈 수 있습니다.\n",
    "\n",
    "![K-Fold](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_0041.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: np_data_xs=(10, 5), np_data_ys=(10,)\n",
      "\n",
      "Cross Valid: KFold(n_splits=2, random_state=None, shuffle=False)\n",
      "idx_train: [5 6 7 8 9], idx_test: [0 1 2 3 4]\n",
      "train shape: np_train_xs=(5, 5), np_train_ys=(5,)\n",
      "test shape: np_test_xs=(5, 5), np_test_ys=(5,)\n",
      "idx_train: [0 1 2 3 4], idx_test: [5 6 7 8 9]\n",
      "train shape: np_train_xs=(5, 5), np_train_ys=(5,)\n",
      "test shape: np_test_xs=(5, 5), np_test_ys=(5,)\n",
      "\n",
      "Cross Valid: RepeatedKFold(n_repeats=2, n_splits=2, random_state=None)\n",
      "idx_train: [0 2 3 7 8], idx_test: [1 4 5 6 9]\n",
      "train shape: np_train_xs=(5, 5), np_train_ys=(5,)\n",
      "test shape: np_test_xs=(5, 5), np_test_ys=(5,)\n",
      "idx_train: [1 4 5 6 9], idx_test: [0 2 3 7 8]\n",
      "train shape: np_train_xs=(5, 5), np_train_ys=(5,)\n",
      "test shape: np_test_xs=(5, 5), np_test_ys=(5,)\n",
      "idx_train: [2 3 6 8 9], idx_test: [0 1 4 5 7]\n",
      "train shape: np_train_xs=(5, 5), np_train_ys=(5,)\n",
      "test shape: np_test_xs=(5, 5), np_test_ys=(5,)\n",
      "idx_train: [0 1 4 5 7], idx_test: [2 3 6 8 9]\n",
      "train shape: np_train_xs=(5, 5), np_train_ys=(5,)\n",
      "test shape: np_test_xs=(5, 5), np_test_ys=(5,)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets, model_selection, linear_model, metrics\n",
    "\n",
    "# 데이터 생성\n",
    "np.random.seed(0)\n",
    "n_samples = 10\n",
    "np_data_xs, np_data_ys = datasets.make_classification(n_samples=n_samples, n_features=5, n_classes=2)\n",
    "print(\"data shape: np_data_xs={}, np_data_ys={}\".format(np_data_xs.shape, np_data_ys.shape))\n",
    "\n",
    "# Cross Validation Methods\n",
    "cvs = [\n",
    "    model_selection.KFold(n_splits=2),\n",
    "    model_selection.RepeatedKFold(n_splits=2, n_repeats=2)\n",
    "]\n",
    "\n",
    "for cv in cvs:\n",
    "    print(\"\\nCross Valid: {}\".format(cv))\n",
    "    for idx_train, idx_valid in cv.split(np_data_xs):\n",
    "        print(\"idx_train: {}, idx_test: {}\".format(idx_train, idx_valid))\n",
    "        np_train_xs, np_train_ys = np_data_xs[idx_train], np_data_ys[idx_train]\n",
    "        np_test_xs, np_test_ys = np_data_xs[idx_valid], np_data_ys[idx_valid]\n",
    "        print(\"train shape: np_train_xs={}, np_train_ys={}\".format(np_train_xs.shape, np_train_ys.shape))\n",
    "        print(\"test shape: np_test_xs={}, np_test_ys={}\".format(np_test_xs.shape, np_test_ys.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified K-Fold\n",
    "\n",
    "Stratified K-Fold 방식은 K-Fold 와 달리 Valid 셋을 분리 할 때, Class 의 비율대로 균등하게 Valid 셋을 분리합니다.\n",
    "\n",
    "![Stratified k-fold](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_0071.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: np_data_xs=(10, 5), np_data_ys=(10,)\n",
      "\n",
      "Cross Valid: StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
      "idx_train: [5 6 7 8 9], idx_test: [0 1 2 3 4]\n",
      "train shape: np_train_xs=(5, 5), np_train_ys=(5,)\n",
      "test shape: np_test_xs=(5, 5), np_test_ys=(5,)\n",
      "idx_train: [0 1 2 3 4], idx_test: [5 6 7 8 9]\n",
      "train shape: np_train_xs=(5, 5), np_train_ys=(5,)\n",
      "test shape: np_test_xs=(5, 5), np_test_ys=(5,)\n",
      "\n",
      "Cross Valid: RepeatedStratifiedKFold(n_repeats=2, n_splits=2, random_state=None)\n",
      "idx_train: [0 3 5 7 8], idx_test: [1 2 4 6 9]\n",
      "train shape: np_train_xs=(5, 5), np_train_ys=(5,)\n",
      "test shape: np_test_xs=(5, 5), np_test_ys=(5,)\n",
      "idx_train: [1 2 4 6 9], idx_test: [0 3 5 7 8]\n",
      "train shape: np_train_xs=(5, 5), np_train_ys=(5,)\n",
      "test shape: np_test_xs=(5, 5), np_test_ys=(5,)\n",
      "idx_train: [3 5 6 7 8], idx_test: [0 1 2 4 9]\n",
      "train shape: np_train_xs=(5, 5), np_train_ys=(5,)\n",
      "test shape: np_test_xs=(5, 5), np_test_ys=(5,)\n",
      "idx_train: [0 1 2 4 9], idx_test: [3 5 6 7 8]\n",
      "train shape: np_train_xs=(5, 5), np_train_ys=(5,)\n",
      "test shape: np_test_xs=(5, 5), np_test_ys=(5,)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets, model_selection, linear_model, metrics\n",
    "\n",
    "# 데이터 생성\n",
    "np.random.seed(0)\n",
    "n_samples = 10\n",
    "np_data_xs, np_data_ys = datasets.make_classification(n_samples=n_samples, n_features=5, n_classes=2)\n",
    "print(\"data shape: np_data_xs={}, np_data_ys={}\".format(np_data_xs.shape, np_data_ys.shape))\n",
    "\n",
    "# Cross Validation Methods\n",
    "cvs = [\n",
    "    model_selection.StratifiedKFold(n_splits=2),\n",
    "    model_selection.RepeatedStratifiedKFold(n_splits=2, n_repeats=2)\n",
    "]\n",
    "\n",
    "for cv in cvs:\n",
    "    print(\"\\nCross Valid: {}\".format(cv))\n",
    "    for idx_train, idx_valid in cv.split(np_data_xs, np_data_ys):\n",
    "        print(\"idx_train: {}, idx_test: {}\".format(idx_train, idx_valid))\n",
    "        np_train_xs, np_train_ys = np_data_xs[idx_train], np_data_ys[idx_train]\n",
    "        np_test_xs, np_test_ys = np_data_xs[idx_valid], np_data_ys[idx_valid]\n",
    "        print(\"train shape: np_train_xs={}, np_train_ys={}\".format(np_train_xs.shape, np_train_ys.shape))\n",
    "        print(\"test shape: np_test_xs={}, np_test_ys={}\".format(np_test_xs.shape, np_test_ys.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group K-Fold\n",
    "\n",
    "Group K-Fold 방식은 Valid 셋을 나눌때 사용자가 정의해준 Group 이 겹치치 않도록 Valid 셋을 분리하는 방식입니다.\n",
    "\n",
    "![Group K-Fold](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_0051.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: np_data_xs=(10, 5), np_data_ys=(10,)\n",
      "\n",
      "Cross Valid: GroupKFold(n_splits=3)\n",
      "idx_train: [0 1 2 3 4 5], idx_test: [6 7 8 9]\n",
      "train shape: np_train_xs=(6, 5), np_train_ys=(6,)\n",
      "test shape: np_test_xs=(4, 5), np_test_ys=(4,)\n",
      "idx_train: [0 1 2 6 7 8 9], idx_test: [3 4 5]\n",
      "train shape: np_train_xs=(7, 5), np_train_ys=(7,)\n",
      "test shape: np_test_xs=(3, 5), np_test_ys=(3,)\n",
      "idx_train: [3 4 5 6 7 8 9], idx_test: [0 1 2]\n",
      "train shape: np_train_xs=(7, 5), np_train_ys=(7,)\n",
      "test shape: np_test_xs=(3, 5), np_test_ys=(3,)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets, model_selection, linear_model, metrics\n",
    "\n",
    "# 데이터 생성\n",
    "np.random.seed(0)\n",
    "n_samples = 10\n",
    "np_data_xs, np_data_ys = datasets.make_classification(n_samples=n_samples, n_features=5, n_classes=2)\n",
    "print(\"data shape: np_data_xs={}, np_data_ys={}\".format(np_data_xs.shape, np_data_ys.shape))\n",
    "data_group = [1, 1, 1, 2, 2, 2, 3, 3, 3, 3]\n",
    "\n",
    "# Cross Validation Methods\n",
    "cvs = [\n",
    "    model_selection.GroupKFold(n_splits=3)\n",
    "]\n",
    "\n",
    "for cv in cvs:\n",
    "    print(\"\\nCross Valid: {}\".format(cv))\n",
    "    for idx_train, idx_valid in cv.split(np_data_xs, np_data_ys, groups=data_group):\n",
    "        print(\"idx_train: {}, idx_test: {}\".format(idx_train, idx_valid))\n",
    "        np_train_xs, np_train_ys = np_data_xs[idx_train], np_data_ys[idx_train]\n",
    "        np_test_xs, np_test_ys = np_data_xs[idx_valid], np_data_ys[idx_valid]\n",
    "        print(\"train shape: np_train_xs={}, np_train_ys={}\".format(np_train_xs.shape, np_train_ys.shape))\n",
    "        print(\"test shape: np_test_xs={}, np_test_ys={}\".format(np_test_xs.shape, np_test_ys.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ShuffleSplit\n",
    "\n",
    "ShuffleSplit은 K-Fold 방법은 훌륭한 대안이 될 수 있습니다. Class 또는 Group 에 상관없이 주어진 사이즈 만큼 랜덤하게 Valid 셋을 분리합니다. \n",
    "\n",
    "![ShuffleSplit](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_0061.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: np_data_xs=(10, 5), np_data_ys=(10,)\n",
      "\n",
      "Cross Valid: ShuffleSplit(n_splits=3, random_state=None, test_size=0.25, train_size=None)\n",
      "idx_train: [1 6 7 8 3 2 0], idx_test: [5 9 4]\n",
      "train shape: np_train_xs=(7, 5), np_train_ys=(7,)\n",
      "test shape: np_test_xs=(3, 5), np_test_ys=(3,)\n",
      "idx_train: [1 4 8 6 2 9 3], idx_test: [0 5 7]\n",
      "train shape: np_train_xs=(7, 5), np_train_ys=(7,)\n",
      "test shape: np_test_xs=(3, 5), np_test_ys=(3,)\n",
      "idx_train: [5 0 3 2 4 1 9], idx_test: [7 8 6]\n",
      "train shape: np_train_xs=(7, 5), np_train_ys=(7,)\n",
      "test shape: np_test_xs=(3, 5), np_test_ys=(3,)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets, model_selection, linear_model, metrics\n",
    "\n",
    "# 데이터 생성\n",
    "np.random.seed(0)\n",
    "n_samples = 10\n",
    "np_data_xs, np_data_ys = datasets.make_classification(n_samples=n_samples, n_features=5, n_classes=2)\n",
    "print(\"data shape: np_data_xs={}, np_data_ys={}\".format(np_data_xs.shape, np_data_ys.shape))\n",
    "\n",
    "# Cross Validation Methods\n",
    "cvs = [\n",
    "    model_selection.ShuffleSplit(n_splits=3, test_size=0.25)\n",
    "]\n",
    "\n",
    "for cv in cvs:\n",
    "    print(\"\\nCross Valid: {}\".format(cv))\n",
    "    for idx_train, idx_valid in cv.split(np_data_xs):\n",
    "        print(\"idx_train: {}, idx_test: {}\".format(idx_train, idx_valid))\n",
    "        np_train_xs, np_train_ys = np_data_xs[idx_train], np_data_ys[idx_train]\n",
    "        np_test_xs, np_test_ys = np_data_xs[idx_valid], np_data_ys[idx_valid]\n",
    "        print(\"train shape: np_train_xs={}, np_train_ys={}\".format(np_train_xs.shape, np_train_ys.shape))\n",
    "        print(\"test shape: np_test_xs={}, np_test_ys={}\".format(np_test_xs.shape, np_test_ys.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Shuffle Split\n",
    "\n",
    "Class의 비율로 주어진 사이즈대로 랜덤하게 Valid 셋을 분리합니다.\n",
    "\n",
    "![Stratified Shuffle Split](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_0091.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: np_data_xs=(10, 5), np_data_ys=(10,)\n",
      "\n",
      "Cross Valid: StratifiedShuffleSplit(n_splits=2, random_state=None, test_size=0.25,\n",
      "            train_size=None)\n",
      "idx_train: [1 9 8 2 4 3 6], idx_test: [5 7 0]\n",
      "train shape: np_train_xs=(7, 5), np_train_ys=(7,)\n",
      "test shape: np_test_xs=(3, 5), np_test_ys=(3,)\n",
      "idx_train: [0 7 5 1 2 9 8], idx_test: [6 3 4]\n",
      "train shape: np_train_xs=(7, 5), np_train_ys=(7,)\n",
      "test shape: np_test_xs=(3, 5), np_test_ys=(3,)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets, model_selection, linear_model, metrics\n",
    "\n",
    "# 데이터 생성\n",
    "np.random.seed(0)\n",
    "n_samples = 10\n",
    "np_data_xs, np_data_ys = datasets.make_classification(n_samples=n_samples, n_features=5, n_classes=2)\n",
    "print(\"data shape: np_data_xs={}, np_data_ys={}\".format(np_data_xs.shape, np_data_ys.shape))\n",
    "\n",
    "# Cross Validation Methods\n",
    "cvs = [\n",
    "    model_selection.StratifiedShuffleSplit(n_splits=2, test_size=0.25)\n",
    "]\n",
    "\n",
    "for cv in cvs:\n",
    "    print(\"\\nCross Valid: {}\".format(cv))\n",
    "    for idx_train, idx_valid in cv.split(np_data_xs, np_data_ys):\n",
    "        print(\"idx_train: {}, idx_test: {}\".format(idx_train, idx_valid))\n",
    "        np_train_xs, np_train_ys = np_data_xs[idx_train], np_data_ys[idx_train]\n",
    "        np_test_xs, np_test_ys = np_data_xs[idx_valid], np_data_ys[idx_valid]\n",
    "        print(\"train shape: np_train_xs={}, np_train_ys={}\".format(np_train_xs.shape, np_train_ys.shape))\n",
    "        print(\"test shape: np_test_xs={}, np_test_ys={}\".format(np_test_xs.shape, np_test_ys.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Shuffle Split¶\n",
    "\n",
    "Group의 비율로 주어진 사이즈대로 랜덤하게 Valid 셋을 분리합니다.\n",
    "\n",
    "![Group Shuffle Split¶](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_0081.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: np_data_xs=(10, 5), np_data_ys=(10,)\n",
      "\n",
      "Cross Valid: GroupShuffleSplit(n_splits=3, random_state=None, test_size=0.25,\n",
      "         train_size=None)\n",
      "idx_train: [0 1 2 6 7 8 9], idx_test: [3 4 5]\n",
      "train shape: np_train_xs=(7, 5), np_train_ys=(7,)\n",
      "test shape: np_test_xs=(3, 5), np_test_ys=(3,)\n",
      "idx_train: [3 4 5 6 7 8 9], idx_test: [0 1 2]\n",
      "train shape: np_train_xs=(7, 5), np_train_ys=(7,)\n",
      "test shape: np_test_xs=(3, 5), np_test_ys=(3,)\n",
      "idx_train: [3 4 5 6 7 8 9], idx_test: [0 1 2]\n",
      "train shape: np_train_xs=(7, 5), np_train_ys=(7,)\n",
      "test shape: np_test_xs=(3, 5), np_test_ys=(3,)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets, model_selection, linear_model, metrics\n",
    "\n",
    "# 데이터 생성\n",
    "np.random.seed(0)\n",
    "n_samples = 10\n",
    "np_data_xs, np_data_ys = datasets.make_classification(n_samples=n_samples, n_features=5, n_classes=2)\n",
    "print(\"data shape: np_data_xs={}, np_data_ys={}\".format(np_data_xs.shape, np_data_ys.shape))\n",
    "data_group = [1, 1, 1, 2, 2, 2, 3, 3, 3, 3]\n",
    "\n",
    "# Cross Validation Methods\n",
    "cvs = [\n",
    "    model_selection.GroupShuffleSplit(n_splits=3, test_size=0.25)\n",
    "]\n",
    "\n",
    "for cv in cvs:\n",
    "    print(\"\\nCross Valid: {}\".format(cv))\n",
    "    for idx_train, idx_valid in cv.split(np_data_xs, np_data_ys, groups=data_group):\n",
    "        print(\"idx_train: {}, idx_test: {}\".format(idx_train, idx_valid))\n",
    "        np_train_xs, np_train_ys = np_data_xs[idx_train], np_data_ys[idx_train]\n",
    "        np_test_xs, np_test_ys = np_data_xs[idx_valid], np_data_ys[idx_valid]\n",
    "        print(\"train shape: np_train_xs={}, np_train_ys={}\".format(np_train_xs.shape, np_train_ys.shape))\n",
    "        print(\"test shape: np_test_xs={}, np_test_ys={}\".format(np_test_xs.shape, np_test_ys.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation Score\n",
    "\n",
    "교차 검증을 위해 데이터 셋을 나누는 함수외에 학습과 평가를 한번에 진행 할 수 있는 함수를 제공합니다. 평가를 위해 제공되는 Scoring 함수는 아래 링크에서 확인 할 수 있습니다.\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values\n",
    "\n",
    "sklearn.metrics 에서 제공되는 함수들은\n",
    "\n",
    "* _score 로 끝나는 함수들은 높은 값이 좋은 것입니다.\n",
    "* _error or _loss 로 끝나는 함수들은 낮은 값이 좋은 것입니다. (make_scorer 사용시 bigger_is_better = False로 설정하세요, 기본 값은 True입니다.)\n",
    "\n",
    "## Evaluation\n",
    "  * [Regressioin](https://comafire.github.io/pages/ml-eval-regression)\n",
    "  * [Classification](https://comafire.github.io/pages/ml-eval-classification)\n",
    "\n",
    "## Regression\n",
    "\n",
    "평가 함수를 사용할 때 주의할 점은 Cross Validation Score는 높은 값이 좋은 것으로 설계되어 있습니다. Regression 의 에러 함수는 평가 함수의 Nagative 값을 넣어주어야 제대로 동작합니다. 그리고, 스코어 값을 다시 에러 함수로 평가할때는 본연의 의미대로 바꾸기 위해 다시 '-' 를 붙여 환원합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: np_data_xs=(1000, 1), np_data_ys=(1000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Scores: [0.26905519 0.31966832 0.30856823 0.30335398 0.28833385], Mean: 0.2977959123991094, STD: 0.017555038647570402\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets, model_selection, linear_model, metrics\n",
    "\n",
    "# 데이터\n",
    "np.random.seed(0)\n",
    "n_samples = 1000\n",
    "np_data_xs, np_data_ys = datasets.make_regression(\n",
    "    n_samples=n_samples, # 데이터 수\n",
    "    n_features=1, # X feature 수\n",
    "    bias=1.0, # Y 절편\n",
    "    noise=0.3, # X 변수들에 더해지는 잡음의 표준 편차\n",
    "    random_state=0) # 난수 발생용 Seed 값\n",
    "print(\"data shape: np_data_xs={}, np_data_ys={}\".format(np_data_xs.shape, np_data_ys.shape))\n",
    "plt.scatter(np_data_xs, np_data_ys, label='data', c='b')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "scores = model_selection.cross_val_score(model, np_data_xs, np_data_ys, cv=5, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "print(\"RMSE Scores: {}, Mean: {}, STD: {}\".format(rmse_scores, rmse_scores.mean(), rmse_scores.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "멀티 클래스의 경우 f1_score 계산시 학습 데이터를 고려하여 'macro', 'wegithed', 'micro', 'samples' 옵션으로 구할 수 있습니다.([Classification](https://comafire.github.io/pages/ml-eval-classification))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: np_data_xs=(10000, 10), np_data_ys=(10000,)\n",
      "F1 Scores: [0.95437945 0.94533971 0.94797739 0.9457868  0.94338936], Mean: 0.9473745411748016, STD: 0.0037940848016819236\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn import datasets, model_selection, ensemble, metrics\n",
    "\n",
    "# 데이터\n",
    "np.random.seed(0)\n",
    "n_samples = 10000\n",
    "np_data_xs, np_data_ys = datasets.make_classification(\n",
    "    n_samples=n_samples, # 데이터 수\n",
    "    n_features=10, # X feature 수\n",
    "    n_informative=3,\n",
    "    n_classes=3, # Y class 수\n",
    "    random_state=0) # 난수 발생용 Seed 값\n",
    "print(\"data shape: np_data_xs={}, np_data_ys={}\".format(np_data_xs.shape, np_data_ys.shape))\n",
    "\n",
    "# 모델\n",
    "model = ensemble.RandomForestClassifier()\n",
    "scores = model_selection.cross_val_score(model, np_data_xs, np_data_ys, cv=5, scoring='f1_macro')\n",
    "f1_scores = scores\n",
    "print(\"F1 Scores: {}, Mean: {}, STD: {}\".format(f1_scores, f1_scores.mean(), f1_scores.std()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nikola": {
   "category": "",
   "date": "2019-05-18",
   "description": "",
   "link": "",
   "slug": "ml-split-train-test",
   "tags": "",
   "title": "Machine Learning - Split Train and Test",
   "type": "text"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
