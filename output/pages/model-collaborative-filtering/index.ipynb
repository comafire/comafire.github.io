{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering \n",
    "\n",
    "협업필터링은 비슷한 성향을 가진 사용자는 비슷한 아이템을 선호 할 것이라는 가정에서 출발한 알고리즘입니다. 사용자가 아이템에 대해서 투표한 평점 로그 데이터를 이용하며, 사용자나 아이템을 기준으로 평점의 유사성을 살피는 Memory-based CF와 평점 데이터를 통해 모델을 만들고 평점을 예측하는 Model-based CF이 있습니다.\n",
    "\n",
    "## Memory-based CF(Collaborative Filtering)\n",
    "\n",
    "평점 행렬을 기억하고 평점 예측을 위해 기억된 행렬 기반으로 유사도 계산을 진행하기 때문에 Memory-based CF라고 불립니다. 이 방법들은 평점 데이터가 충분히 있을 경우 간단하면서 좋은 성능을 나타내지만, 평점 데이터가 없는 새로운 유저 및 아이템 추가시 대응이 어렵다는 단점이 있습니다.\n",
    "\n",
    "![matrix](https://cdn-images-1.medium.com/max/1600/1*NTd4NH0H1mrSr01Ppr58dg.png)\n",
    "\n",
    "**User-based CF**\n",
    "* 평점 행렬에서 사용자 평점 벡터 기준으로 유사한 사용자를 찾아서 이를 기반으로 원하는 아이템의 평점을 계산하는 방법\n",
    "* 예) E 사용자의 TV 아이템 평점을 예측하고자 할때, E 사용자와 비슷한 아이템 평점 벡터를 가진 B, C 사용자의 TV 아이템 평점벡터를 기준으로 예측\n",
    "  \n",
    "**Item-based CF**\n",
    "* 평점 행렬에서 아이템 평점 벡터 기준으로 유사한 아이템를 찾아서 이를 기반으로 원하는 사용지의 평점을 계산하는 방법\n",
    "* 예) TV 아이템의 E 사용자 평점을 예측하고자 할대, TV 아이템과 비슷한 사용자 평점 벡터를 가진 게임패트 아이템의 사용자 평점벡터를 기준으로 예측\n",
    "\n",
    "\n",
    "유사도 계산을 위해 surprise 패키지는 다음과 같은 유사도 기준을 제공합니다.\n",
    "* 평균제곱차이 유사도 ('msd': Mean Squared Difference Similarity)\n",
    "* 코사인 유사도 ('cosine': Cosine Similarity)\n",
    "* 피어슨 유사도 ('psearson': Pearson Similarity)\n",
    "* 피어슨-베이스라인 유사도 ('pearson_baseline': Pearson-Baseline Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_data.shape=(100000, 4)\n",
      "user_id       object\n",
      "item_id       object\n",
      "rating       float64\n",
      "timestamp     object\n",
      "dtype: object\n",
      "  user_id item_id  rating  timestamp\n",
      "0     196     242     3.0  881250949\n",
      "1     186     302     3.0  891717742\n",
      "2      22     377     1.0  878887116\n",
      "3     244      51     2.0  880606923\n",
      "4     166     346     1.0  886397596\n",
      "       user_id item_id         rating  timestamp\n",
      "count   100000  100000  100000.000000     100000\n",
      "unique     943    1682            NaN      49282\n",
      "top        405      50            NaN  891033606\n",
      "freq       737     583            NaN         12\n",
      "mean       NaN     NaN       3.529860        NaN\n",
      "std        NaN     NaN       1.125674        NaN\n",
      "min        NaN     NaN       1.000000        NaN\n",
      "25%        NaN     NaN       3.000000        NaN\n",
      "50%        NaN     NaN       4.000000        NaN\n",
      "75%        NaN     NaN       4.000000        NaN\n",
      "max        NaN     NaN       5.000000        NaN\n",
      "(100000, 4) (90000, 4) (10000, 4)\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "MAE (testset)     0.7832  0.7878  0.7859  0.7856  0.0019  \n",
      "RMSE (testset)    0.9920  0.9944  0.9936  0.9933  0.0010  \n",
      "Fit time          0.17    0.19    0.19    0.19    0.01    \n",
      "Test time         5.68    5.72    5.97    5.79    0.13    \n",
      "Test RMSE=0.9919432379164125\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "MAE (testset)     0.8117  0.8131  0.8078  0.8108  0.0023  \n",
      "RMSE (testset)    1.0238  1.0268  1.0199  1.0235  0.0028  \n",
      "Fit time          0.88    0.89    0.94    0.90    0.02    \n",
      "Test time         6.06    5.92    6.05    6.01    0.06    \n",
      "Test RMSE=1.0224081647696446\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "MAE (testset)     0.8114  0.8102  0.8172  0.8129  0.0031  \n",
      "RMSE (testset)    1.0219  1.0219  1.0286  1.0241  0.0032  \n",
      "Fit time          1.46    1.45    1.37    1.43    0.04    \n",
      "Test time         5.73    6.43    6.56    6.24    0.36    \n",
      "Test RMSE=1.0245770389211275\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "MAE (testset)     0.7847  0.7917  0.7826  0.7863  0.0039  \n",
      "RMSE (testset)    0.9887  0.9978  0.9883  0.9916  0.0044  \n",
      "Fit time          0.29    0.30    0.28    0.29    0.01    \n",
      "Test time         7.29    6.82    6.83    6.98    0.22    \n",
      "Test RMSE=0.9876095694171025\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "MAE (testset)     0.8285  0.8282  0.8278  0.8282  0.0003  \n",
      "RMSE (testset)    1.0435  1.0395  1.0430  1.0420  0.0018  \n",
      "Fit time          1.67    1.65    1.58    1.63    0.04    \n",
      "Test time         6.60    6.87    6.93    6.80    0.14    \n",
      "Test RMSE=1.0401501772737274\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "MAE (testset)     0.8447  0.8396  0.8426  0.8423  0.0021  \n",
      "RMSE (testset)    1.0542  1.0525  1.0548  1.0539  0.0010  \n",
      "Fit time          2.51    2.35    2.57    2.48    0.09    \n",
      "Test time         6.48    6.90    6.39    6.59    0.22    \n",
      "Test RMSE=1.051538692275093\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, preprocessing, model_selection, metrics\n",
    "import surprise as sp\n",
    "\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# 데이터\n",
    "sp_data = sp.Dataset.load_builtin('ml-100k')\n",
    "df_data = pd.DataFrame(sp_data.raw_ratings, columns=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "print(\"df_data.shape={}\".format(df_data.shape))\n",
    "print(df_data.dtypes)\n",
    "print(df_data.head())\n",
    "print(df_data.describe(include='all'))\n",
    "\n",
    "df_train, df_test = model_selection.train_test_split(df_data, test_size=0.1)\n",
    "print(df_data.shape, df_train.shape, df_test.shape)\n",
    "\n",
    "# 전처리 \n",
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = sp.Reader(rating_scale=(1, 5))\n",
    "sp_data = sp.Dataset.load_from_df(df_train[['user_id', 'item_id', 'rating']], reader)\n",
    "# surprise model.test 의 input shape => [(user_id, item_id, rating)]\n",
    "sp_test = [(row['user_id'], row['item_id'], row['rating']) for i, row in df_test.iterrows()]\n",
    "\n",
    "# 모델\n",
    "models = [\n",
    "    sp.KNNBasic(sim_options={'name' : 'msd'}), \n",
    "    sp.KNNBasic(sim_options={'name' : 'cosine'}),\n",
    "    sp.KNNBasic(sim_options={'name' : 'pearson'}),\n",
    "    sp.KNNBasic(sim_options={'name' : 'msd', 'user_based': False}),\n",
    "    sp.KNNBasic(sim_options={'name' : 'cosine', 'user_based': False}),\n",
    "    sp.KNNBasic(sim_options={'name' : 'pearson', 'user_based': False})    \n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    # 학습\n",
    "    sp.model_selection.cross_validate(model, sp_data, measures=['RMSE', 'MAE'], cv=3, verbose=True)\n",
    "    \n",
    "    # 평가\n",
    "    sp_pred = model.test(sp_test)\n",
    "    rmse = sp.accuracy.rmse(sp_pred, verbose=False)\n",
    "    print(\"Test RMSE={}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict() 함수를 통해 한 데이터 셋에 대해서 예측 평점을 구할 수 있으며, Top-N 개의 비슷한 아이템이나, 사용자를 찾을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE=1.051538692275093\n"
     ]
    }
   ],
   "source": [
    "# 평가: by predict\n",
    "tests = []\n",
    "preds = []\n",
    "for row in sp_test:\n",
    "    tests.append(row[2])\n",
    "    pred = model.predict(row[0], row[1], row[2])\n",
    "    preds.append(pred.est)\n",
    "\n",
    "rmse = math.sqrt(metrics.mean_squared_error(tests, preds))\n",
    "print(\"Test RMSE={}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-N Similar Users\n",
      "raw_uid:22 == inner_uid:493\n",
      "top-5 inner_uids: [3, 32, 85, 100, 174]\n",
      "top-5 raw_uids: ['803', '703', '494', '787', '802']\n",
      "\n",
      "Top-N Similar Items\n",
      "raw_iid:377 == inner_iid:610\n",
      "top-5 inner_iids: [1, 15, 30, 47, 56]\n",
      "top-5 raw_iids: ['597', '402', '356', '365', '406']\n"
     ]
    }
   ],
   "source": [
    "print(\"Top-N Similar Users\")\n",
    "user_model = models[0] # sp.KNNBasic(sim_options={'name' : 'msd'})\n",
    "raw_uid = '22'\n",
    "inner_uid = user_model.trainset.to_inner_uid(raw_uid)\n",
    "raw_uid = user_model.trainset.to_raw_uid(inner_uid)\n",
    "print(\"raw_uid:{} == inner_uid:{}\".format(raw_uid, inner_uid))\n",
    "\n",
    "top_inner_uids = user_model.get_neighbors(inner_uid, k=5)\n",
    "print(\"top-5 inner_uids: {}\".format(top_inner_uids))\n",
    "top_raw_uids = [user_model.trainset.to_raw_uid(top_inner_uid) for top_inner_uid in top_inner_uids]\n",
    "print(\"top-5 raw_uids: {}\".format(top_raw_uids))\n",
    "\n",
    "print(\"\\nTop-N Similar Items\")\n",
    "item_model = models[3] # sp.KNNBasic(sim_options={'name' : 'msd', 'user_based': False})\n",
    "raw_iid = '377'\n",
    "inner_iid = item_model.trainset.to_inner_iid(raw_iid)\n",
    "raw_iid = item_model.trainset.to_raw_iid(inner_iid)\n",
    "print(\"raw_iid:{} == inner_iid:{}\".format(raw_iid, inner_iid))\n",
    "\n",
    "top_inner_iids = item_model.get_neighbors(inner_iid, k=5)\n",
    "print(\"top-5 inner_iids: {}\".format(top_inner_iids))\n",
    "top_raw_iids = [item_model.trainset.to_raw_iid(top_inner_iid) for top_inner_iid in top_inner_iids]\n",
    "print(\"top-5 raw_iids: {}\".format(top_raw_iids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-based CF\n",
    "\n",
    "평점 데이터를 통해 모델을 만드는 방법은 다양한 접근이 가능하지만, 그 중 행렬의 연산을 이용하여 특징벡터를 추출하여 사용하는 Matrix Factorization을 많이 사용합니다. Matrix Factorization 문제에 대한 해를 찾는 방법은 여러가지가 있지만 그 중에서도 일반적으로 SVD(Singular Value Decomposition)방법을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_data.shape=(100000, 4)\n",
      "user_id       object\n",
      "item_id       object\n",
      "rating       float64\n",
      "timestamp     object\n",
      "dtype: object\n",
      "  user_id item_id  rating  timestamp\n",
      "0     196     242     3.0  881250949\n",
      "1     186     302     3.0  891717742\n",
      "2      22     377     1.0  878887116\n",
      "3     244      51     2.0  880606923\n",
      "4     166     346     1.0  886397596\n",
      "       user_id item_id         rating  timestamp\n",
      "count   100000  100000  100000.000000     100000\n",
      "unique     943    1682            NaN      49282\n",
      "top        405      50            NaN  891033606\n",
      "freq       737     583            NaN         12\n",
      "mean       NaN     NaN       3.529860        NaN\n",
      "std        NaN     NaN       1.125674        NaN\n",
      "min        NaN     NaN       1.000000        NaN\n",
      "25%        NaN     NaN       3.000000        NaN\n",
      "50%        NaN     NaN       4.000000        NaN\n",
      "75%        NaN     NaN       4.000000        NaN\n",
      "max        NaN     NaN       5.000000        NaN\n",
      "(100000, 4) (90000, 4) (10000, 4)\n",
      "Evaluating RMSE, MAE of algorithm SVD on 3 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Mean    Std     \n",
      "MAE (testset)     0.7494  0.7447  0.7462  0.7468  0.0020  \n",
      "RMSE (testset)    0.9492  0.9441  0.9432  0.9455  0.0027  \n",
      "Fit time          2.08    2.01    2.15    2.08    0.06    \n",
      "Test time         0.39    0.40    0.41    0.40    0.01    \n",
      "Test RMSE=0.9465768404143768\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, preprocessing, model_selection, metrics\n",
    "import surprise as sp\n",
    "\n",
    "# 데이터\n",
    "sp_data = sp.Dataset.load_builtin('ml-100k')\n",
    "df_data = pd.DataFrame(sp_data.raw_ratings, columns=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"])\n",
    "print(\"df_data.shape={}\".format(df_data.shape))\n",
    "print(df_data.dtypes)\n",
    "print(df_data.head())\n",
    "print(df_data.describe(include='all'))\n",
    "\n",
    "df_train, df_test = model_selection.train_test_split(df_data, test_size=0.1)\n",
    "print(df_data.shape, df_train.shape, df_test.shape)\n",
    "\n",
    "# 전처리 \n",
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = sp.Reader(rating_scale=(1, 5))\n",
    "sp_data = sp.Dataset.load_from_df(df_train[['user_id', 'item_id', 'rating']], reader)\n",
    "# surprise model.test 의 input shape => [(user_id, item_id, rating)]\n",
    "sp_test = [(row['user_id'], row['item_id'], row['rating']) for i, row in df_test.iterrows()]\n",
    "\n",
    "# 모델\n",
    "models = [\n",
    "    sp.SVD(n_factors=20),    \n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    # 학습\n",
    "    sp.model_selection.cross_validate(model, sp_data, measures=['RMSE', 'MAE'], cv=3, verbose=True)\n",
    "    \n",
    "    # 평가\n",
    "    sp_pred = model.test(sp_test)\n",
    "    rmse = sp.accuracy.rmse(sp_pred, verbose=False)\n",
    "    print(\"Test RMSE={}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict() 함수를 통해 한 데이터 셋에 대해서 예측 평점을 구할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE=0.9465768404143768\n"
     ]
    }
   ],
   "source": [
    "# 평가: by predict\n",
    "tests = []\n",
    "preds = []\n",
    "for row in sp_test:\n",
    "    tests.append(row[2])\n",
    "    pred = model.predict(row[0], row[1], row[2])\n",
    "    preds.append(pred.est)\n",
    "\n",
    "rmse = math.sqrt(metrics.mean_squared_error(tests, preds))\n",
    "print(\"Test RMSE={}\".format(rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nikola": {
   "category": "",
   "date": "2019-05-04",
   "description": "",
   "link": "",
   "slug": "model-collaborative-filtering",
   "tags": "",
   "title": "Collaborative Filtering",
   "type": "text"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
