
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>이전 글에서 Jupyter를 설치하고 Pelican을 이용하여 블로깅에 사용할수 있는 방법에 대해알아봤습니다.
<a href="https://comafire.github.io/posts/2016-Jupyter-From-Dev-To-Blogging">Jupyter-From-Dev-To-Blogging</a></p>
<p>이제 Jupyter 에서 로컬 노트북상에 Apache Spark을 사용할 수 있도록 연동해 보도록 하겠습니다.</p>
<!-- TEASER_END -->

<h3 id="Apache-Spark">Apache Spark<a class="anchor-link" href="#Apache-Spark">&#182;</a></h3><p>Spark으로 무엇을 해보려면 클러스터가 있어야 한다는 선입견에 빠지기 쉽습니다만, 요즘 보편화 되어 있는 멀티 코어 노트북의 장점을 복잡한 멀티코어, 멀티스레드 프로그래밍 없이 적극 활용가능하다는 측면에서 클러스터가 아닌 로컬 노트북상에서도 충분한 활용성이 있습니다.</p>
<p>먼저, Java 가 설치되어 있는지 확인합니다.</p>
<div class="highlight"><pre><span></span>&gt; which java
/usr/bin/java
&gt; java -version
java version <span class="s2">&quot;1.8.0_91&quot;</span>
Java<span class="o">(</span>TM<span class="o">)</span> SE Runtime Environment <span class="o">(</span>build <span class="m">1</span>.8.0_91-b14<span class="o">)</span>
Java HotSpot<span class="o">(</span>TM<span class="o">)</span> <span class="m">64</span>-Bit Server VM <span class="o">(</span>build <span class="m">25</span>.91-b14, mixed mode<span class="o">)</span>
</pre></div>
<p>만약 설치가 안되어 있으면  <a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html">http://www.oracle.com/technetwork/java/javase/downloads/index.html</a> 오라클 홈페이지 상에서 다운받아 설치합니다.</p>
<p>다음으로 brew 를 이용하여 scala 를 설치합니다.</p>
<div class="highlight"><pre><span></span>&gt; brew install scala
</pre></div>
<p>이제 Spark을 설치합니다. <a href="https://spark.apache.org/downloads.html">https://spark.apache.org/downloads.html</a> 사이트에서 원하는 버전의 Spark 을 다운로드 받습니다.</p>
<p>로컬에 Spark을 설치하는 것은 간단히 Spark을 받아 압축을 푸는 것으로 끝납니다. 편의를 위해서 심볼릭 링크를 걸어둡니다.</p>
<div class="highlight"><pre><span></span>&gt; <span class="nb">cd</span> /usr/local
&gt; mv ~/Downloads/spark-2.0.0-bin-hadoop2.7.tgz ./
&gt; tar -zxvf spark-2.0.0-bin-hadoop2.7.tgz
&gt; ln -s spark-2.0.0-bin-hadoop2.7 spark
</pre></div>
<p>이제 쉘 환경설정파일에 환경변수를 설정합니다.</p>

<pre><code>&gt; vi ~/.bash_profile

export PATH="/usr/local/sbin:$PATH"

export JAVA_HOME=$(/usr/libexec/java_home)
export SCALA_HOME=/usr/local/bin/scala
export PATH=$PATH:$SCALA_HOME/bin

export SPARK_HOME=/usr/local/spark
export PATH=$PATH:$SPARK_HOME/bin
export PYTHONPATH=$SPARK_HOME/python/:$PYTHONPATH
export PYTHONPATH=$SPARK_HOME/python/lib/py4j-0.10-src.zip:$PYTHONPATH

export PYTHON=/usr/local/bin/python</code></pre>
<p>py4j 라이브러리의 경우 설치한 spark 안에 라이브러리 버전을 확인하여 이름을 넣어주세요.</p>
<p>이제 Jupyter 와 연동하기 위해 Apache Toree를 설치합니다. 기존에 Jupyter와 Spark을 연결하는 방식이 좀 복잡했는데 Toree 를 이용하면 간단하게 Jupyter 와 연동이 가능합니다.</p>
<div class="highlight"><pre><span></span>&gt; pip install --pre toree
&gt; jupyter toree install
</pre></div>
<p>이제 지금 블로깅하고 있는 Jupyter의 Kernel을 Toree리로 변경하고 간단히 로컬에 설치된 Spark를 테스트해보겠습니다.</p>
<p>먼저 Scala를 통해 Spark소스안에 포함된 예제 json 파일을 dataframe으로 읽어보겠습니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-scala"><pre><span></span><span class="k">import</span> <span class="nn">org.apache.spark.SparkConf</span>
<span class="k">import</span> <span class="nn">org.apache.spark.SparkContext</span>
<span class="k">import</span> <span class="nn">org.apache.spark.sql.SQLContext</span>

<span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="o">(</span><span class="s">&quot;/usr/local/spark/examples/src/main/resources/people.json&quot;</span><span class="o">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>+----+-------+
| age|   name|
+----+-------+
|null|Michael|
|  30|   Andy|
|  19| Justin|
+----+-------+

</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>다음으로 Toree의 Magics 통해 Python과 R로 Spark을 사용해보겠습니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-scala"><pre><span></span><span class="o">%%</span><span class="nc">PySpark</span>
<span class="n">df</span> <span class="k">=</span> <span class="n">sqlContext</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">json</span><span class="o">(</span><span class="s">&quot;/usr/local/spark/examples/src/main/resources/people.json&quot;</span><span class="o">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">show</span><span class="o">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[2]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>+----+-------+
| age|   name|
+----+-------+
|null|Michael|
|  30|   Andy|
|  19| Justin|
+----+-------+

</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>이 외에도 다양한 Magics를 지원합니다. 더 자세한 사용법은 아래 링크를 참조하세요.
<a href="https://github.com/apache/incubator-toree/blob/master/etc/examples/notebooks/magic-tutorial.ipynb">https://github.com/apache/incubator-toree/blob/master/etc/examples/notebooks/magic-tutorial.ipynb</a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-scala"><pre><span></span><span class="o">%%</span><span class="nc">SparkR</span>
<span class="n">df</span> <span class="k">&lt;-</span> <span class="n">jsonFile</span><span class="o">(</span><span class="n">sqlContext</span><span class="o">,</span> <span class="s">&quot;/usr/local/spark/examples/src/main/resources/people.json&quot;</span><span class="o">)</span>
<span class="n">showDF</span><span class="o">(</span><span class="n">df</span><span class="o">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[4]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>+----+-------+
| age|   name|
+----+-------+
|null|Michael|
|  30|   Andy|
|  19| Justin|
+----+-------+</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>한가지 아쉬운 점은 Toree 내에서 Python과 R의 경우 코드 자동완성 기능이 Spark함수 밖에 안된다는 것입니다.</p>
<p>Python과 R의 경우 따로 Python과 R커널에서 Spark을 띄워서 사용하면 Spark외 함수에 대한 코드 자동완성 기능을 사용할 수 있습니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-scala"><pre><span></span>
</pre></div>

    </div>
</div>
</div>

</div>
 

