{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# macOS 에서 pyspark SparkContext 생성 시 java.net.BindException 에러\n",
    "\n",
    "macOS 에서 Jupyter 노트북을 통해 로컬 pyspark 의 SparkContext 생성시 아래와 같이 java.net.BindException 에러가 나는 경우가 있습니다. \n",
    "\n",
    "```python\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"spark\")\n",
    "spark = spark.config(\"spark.driver.memory\", \"8g\")\n",
    "spark = spark.config(\"spark.executor.memory\", \"8g\")\n",
    "spark = spark.config(\"spark.python.worker.memory\", \"8g\")\n",
    "spark = spark.getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "```\n",
    "\n",
    "<!-- TEASER_END -->\n",
    "\n",
    "```bash\n",
    "ERROR SparkContext: Error initializing SparkContext.\n",
    "java.net.BindException: Can't assign requested address: Service 'sparkDriver' failed after 16 retries (on a random free port)! Consider explicitly setting the appropriate binding address for the service 'sparkDriver' (for example spark.driver.bindAddress for SparkDriver) to the correct binding address.\n",
    "\tat java.base/sun.nio.ch.Net.bind0(Native Method)\n",
    "\tat java.base/sun.nio.ch.Net.bind(Net.java:469)\n",
    "\tat java.base/sun.nio.ch.Net.bind(Net.java:458)\n",
    "\tat java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:220)\n",
    "\tat io.netty.channel.socket.nio.NioServerSocketChannel.doBind(NioServerSocketChannel.java:132)\n",
    "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.bind(AbstractChannel.java:551)\n",
    "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.bind(DefaultChannelPipeline.java:1346)\n",
    "\tat io.netty.channel.AbstractChannelHandlerContext.invokeBind(AbstractChannelHandlerContext.java:503)\n",
    "\tat io.netty.channel.AbstractChannelHandlerContext.bind(AbstractChannelHandlerContext.java:488)\n",
    "\tat io.netty.channel.DefaultChannelPipeline.bind(DefaultChannelPipeline.java:985)\n",
    "\tat io.netty.channel.AbstractChannel.bind(AbstractChannel.java:247)\n",
    "\tat io.netty.bootstrap.AbstractBootstrap$2.run(AbstractBootstrap.java:344)\n",
    "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:163)\n",
    "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:510)\n",
    "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:518)\n",
    "\tat io.netty.util.concurrent.SingleThreadEventExecutor$6.run(SingleThreadEventExecutor.java:1044)\n",
    "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
    "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
    "\tat java.base/java.lang.Thread.run(Thread.java:830)\n",
    "```\n",
    "\n",
    "이는 macOS 의 hostname 으로 localhost 를 찾지 못해 일어나는 현상으로 SPARK_LOCAL_IP 라는 환경 변수를 설정해주어 해결할 수 있습니다.\n",
    "\n",
    "이를 설정하는 방법은 아래와 같이 python 코드상에서 환경 설정 변수를 지정하는 방법\n",
    "\n",
    "```python\n",
    "os.environ[\"SPARK_LOCAL_IP\"] = \"127.0.0.1\"\n",
    "```\n",
    "\n",
    "shell 의 환경 변수에 설정하는 방법\n",
    "\n",
    "```bash\n",
    "export SPARK_LOCAL_IP=\"127.0.0.1\"\n",
    "```\n",
    "\n",
    "또는 spark의 환경 설정 파일인 spark-env.sh 파일에 설정하는 방법이 있습니다.\n",
    "\n",
    "```bash\n",
    "> vi $SPARK_HOME/conf/spark-env.sh\n",
    "\n",
    "...\n",
    "# Options read by executors and drivers running inside the cluster\n",
    "# - SPARK_LOCAL_IP, to set the IP address Spark binds to on this node\n",
    "# - SPARK_PUBLIC_DNS, to set the public DNS name of the driver program\n",
    "# - SPARK_LOCAL_DIRS, storage directories to use on this node for shuffle and RDD data\n",
    "# - MESOS_NATIVE_JAVA_LIBRARY, to point to your libmesos.so if you use Mesos\n",
    "\n",
    "SPARK_LOCAL_IP=\"127.0.0.1\"\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nikola": {
   "category": "",
   "date": "2020-03-14",
   "description": "",
   "link": "",
   "slug": "2020-pyspark-macos-bind-error",
   "tags": "",
   "title": "macOS 에서 pyspark SparkContext 생성 시 java.net.BindException 에러",
   "type": "text"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
