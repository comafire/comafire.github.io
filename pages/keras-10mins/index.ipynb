{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "\n",
    "[Keras](https://keras.io/)는 Deep Learning 을 위한 배우고 사용하기 위한 API 를 지향하면서 다양한 백엔드 엔진에 대한 통일된 API 를 제공합니다. 몇 줄 안되는 코드로 Deep Learning 구조들을 쉽게 만들고 시험해 볼수 있습니다.\n",
    "\n",
    "![Deep Learning Framework Power Scores 2018](https://s3.amazonaws.com/keras.io/img/dl_frameworks_power_scores.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas ver=0.24.1\n",
      "numpy ver=1.16.2\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=5)\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None) \n",
    "pd.set_option('display.max_columns', None) \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.options.display.float_format = '{:,.5f}'.format\n",
    "\n",
    "print(\"pandas ver={}\".format(pd.__version__))\n",
    "print(\"numpy ver={}\".format(np.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras 에서는 2가지 방식의 딥러닝 모델 구성 방식을 제공합니다.\n",
    "\n",
    "* [Sequential Model](https://keras.io/getting-started/sequential-model-guide/)\n",
    "  * 스택처럼 쌓아서 만드는 단일 구조의 딥러닝 모델을 간편하게 설계할 수 있습니다.\n",
    "* [Function API](https://keras.io/getting-started/functional-api-guide/)\n",
    "  * 다양한 모델을 엮어 만드는 복잡한 구조의 딥러닝 모델을 설계할 수 있습니다.\n",
    "  * multi-output models, directed acyclic graphs, 또는 shared layers를 가지는 모델들의 설계가 가능합니다.\n",
    "  \n",
    "MNIST 데이터셋을 2가지 방식으로 DNN을 구축해보면서 각 구현 방식의 차이점에 대해서 알아봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r=60000, w=28, h=28\n",
      "(60000, 784)\n",
      "(10000, 784)\n",
      "(60000, 10)\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# MNIST 샘플 데이터\n",
    "(np_train_xs, np_train_ys), (np_test_xs, np_test_ys) = mnist.load_data()\n",
    "\n",
    "r, w, h = np_train_xs.shape\n",
    "print(\"r={}, w={}, h={}\".format(r, w, h))\n",
    "\n",
    "# 전처리 - 28x28 2D 이미지를 DNN 모델링을 위해 784 1D 로 변환합니다. \n",
    "dim_x = w * h\n",
    "np_train_xs = np_train_xs.reshape(-1, dim_x).astype('float32')\n",
    "np_test_xs = np_test_xs.reshape(-1, dim_x).astype('float32')\n",
    "print(np_train_xs.shape)\n",
    "print(np_test_xs.shape)\n",
    "\n",
    "# 전처리 - 0~1 사이로 데이터 Min Max Scaling\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "np_train_xs = scaler.fit_transform(np_train_xs)\n",
    "np_test_xs = scaler.transform(np_test_xs)\n",
    "\n",
    "# 전처리 - 레이블을 Ont Hot 인코팅 \n",
    "from keras.utils import np_utils\n",
    "\n",
    "n_class = 10\n",
    "np_train_ys = np_utils.to_categorical(np_train_ys, n_class)\n",
    "np_test_ys = np_utils.to_categorical(np_test_ys, n_class)\n",
    "print(np_train_ys.shape)\n",
    "print(np_train_ys[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 384)               301440    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               49280     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 359,626\n",
      "Trainable params: 359,626\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers, models, optimizers\n",
    "\n",
    "# Sequential Model를 사용\n",
    "def dnn_seq(n_i, n_hs, n_o):\n",
    "    m = models.Sequential()\n",
    "    m.add(layers.Dense(n_i, activation='relu', input_shape=(n_i,)))\n",
    "    for l, n_h in enumerate(n_hs):\n",
    "        m.add(layers.Dense(n_h, activation='relu'))\n",
    "    m.add(layers.Dense(n_o, activation = 'softmax'))\n",
    "    sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    m.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return m\n",
    "\n",
    "class DnnSeq(models.Sequential):\n",
    "    def __init__(self, n_i, n_hs, n_o):\n",
    "        super().__init__()\n",
    "        self.add(layers.Dense(n_i, activation='relu', input_shape=(n_i,)))\n",
    "        for l, n_h in enumerate(n_hs):\n",
    "            self.add(layers.Dense(n_h, activation='relu'))\n",
    "        self.add(layers.Dense(n_o, activation = 'softmax'))\n",
    "        sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        self.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Function API를 사용\n",
    "def dnn_func(n_i, n_hs, n_o):\n",
    "    i = layers.Input(shape = (n_i,))\n",
    "    for l, n_h in enumerate(n_hs):\n",
    "        if l == 0:\n",
    "            h = layers.Dense(n_h, activation = 'relu')(i)            \n",
    "        else:\n",
    "            h = layers.Dense(n_h, activation = 'relu')(h)    \n",
    "    o = layers.Dense(n_o, activation = 'softmax')(h)\n",
    "    m = models.Model(inputs=[i], outputs=[o])\n",
    "    sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    m.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return m\n",
    "\n",
    "class DnnFunc(models.Model):\n",
    "    def __init__(self, n_i, n_hs, n_o):\n",
    "        i = layers.Input(shape = (n_i,))\n",
    "        for l, n_h in enumerate(n_hs):\n",
    "            if l == 0:\n",
    "                h = layers.Dense(n_h, activation = 'relu')(i)            \n",
    "            else:\n",
    "                h = layers.Dense(n_h, activation = 'relu')(h)    \n",
    "        o = layers.Dense(n_o, activation = 'softmax')(h)\n",
    "        \n",
    "        super().__init__(inputs=[i], outputs=[o])\n",
    "        sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        self.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "#model = dnn_seq(n_i = dim_x, n_hs = [384, 128, 64], n_o = n_class)\n",
    "#model = DnnSeq(n_i = dim_x, n_hs = [384, 128, 64], n_o = n_class)\n",
    "#model = dnn_func(n_i = dim_x, n_hs = [384, 128, 64], n_o = n_class)\n",
    "model = DnnFunc(n_i = dim_x, n_hs = [384, 128, 64], n_o = n_class)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.4390 - acc: 0.8731 - val_loss: 0.1959 - val_acc: 0.9461\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.1683 - acc: 0.9508 - val_loss: 0.1449 - val_acc: 0.9585\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.1157 - acc: 0.9659 - val_loss: 0.1164 - val_acc: 0.9668\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0860 - acc: 0.9745 - val_loss: 0.1134 - val_acc: 0.9660\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0669 - acc: 0.9796 - val_loss: 0.0897 - val_acc: 0.9734\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0509 - acc: 0.9854 - val_loss: 0.0908 - val_acc: 0.9717\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0400 - acc: 0.9881 - val_loss: 0.0889 - val_acc: 0.9733\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0320 - acc: 0.9910 - val_loss: 0.0808 - val_acc: 0.9758\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0247 - acc: 0.9933 - val_loss: 0.0783 - val_acc: 0.9770\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.0189 - acc: 0.9949 - val_loss: 0.0767 - val_acc: 0.9792\n",
      "10000/10000 [==============================] - 0s 9us/step\n",
      "[0.07681204915992566, 0.9782000082731247]\n"
     ]
    }
   ],
   "source": [
    "# 학습과 평가\n",
    "history = model.fit(np_train_xs, np_train_ys, epochs=10, batch_size=100, validation_split=0.2)\n",
    "eval = model.evaluate(np_test_xs, np_test_ys, batch_size=100)\n",
    "print(eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nikola": {
   "category": "",
   "date": "2019-03-09",
   "description": "",
   "link": "",
   "slug": "keras-10mins",
   "tags": "",
   "title": "Keras 10분만에 훑어보기",
   "type": "text"
  },
  "notebookId": 2469278771832403,
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
