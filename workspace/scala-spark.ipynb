{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.sql.SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val conf = new SparkConf()\n",
    "conf.set(\"spark.driver.allowMultipleContexts\", \"true\")\n",
    "conf.setAppName(\"spark-scala\")\n",
    "conf.setMaster(\"local[*]\")\n",
    "val sc = new SparkContext(conf)\n",
    "val sqlContext = new SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Unknown\n",
       "Message: Unable to retrieve error!\n",
       "StackTrace: "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = sqlContext.read.json(\"people.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: org.apache.spark.SparkException\n",
       "Message: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:\n",
       "org.apache.spark.SparkContext.<init>(SparkContext.scala:82)\n",
       "org.apache.toree.kernel.api.Kernel$$anonfun$initializeSparkContext$1.apply$mcV$sp(Kernel.scala:396)\n",
       "org.apache.toree.kernel.api.Kernel$$anonfun$initializeSparkContext$1.apply(Kernel.scala:396)\n",
       "org.apache.toree.kernel.api.Kernel$$anonfun$initializeSparkContext$1.apply(Kernel.scala:396)\n",
       "org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
       "org.apache.toree.kernel.api.Kernel.initializeSparkContext(Kernel.scala:395)\n",
       "org.apache.toree.kernel.api.Kernel.createSparkContext(Kernel.scala:349)\n",
       "org.apache.toree.kernel.api.Kernel.createSparkContext(Kernel.scala:370)\n",
       "org.apache.toree.boot.layer.StandardComponentInitialization$class.initializeSparkContext(ComponentInitialization.scala:101)\n",
       "org.apache.toree.Main$$anon$1.initializeSparkContext(Main.scala:35)\n",
       "org.apache.toree.boot.layer.StandardComponentInitialization$class.initializeComponents(ComponentInitialization.scala:86)\n",
       "org.apache.toree.Main$$anon$1.initializeComponents(Main.scala:35)\n",
       "org.apache.toree.boot.KernelBootstrap.initialize(KernelBootstrap.scala:89)\n",
       "org.apache.toree.Main$delayedInit$body.apply(Main.scala:40)\n",
       "scala.Function0$class.apply$mcV$sp(Function0.scala:40)\n",
       "scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)\n",
       "scala.App$$anonfun$main$1.apply(App.scala:71)\n",
       "scala.App$$anonfun$main$1.apply(App.scala:71)\n",
       "scala.collection.immutable.List.foreach(List.scala:318)\n",
       "scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)\n",
       "StackTrace: org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2257)\n",
       "org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2239)\n",
       "scala.Option.foreach(Option.scala:236)\n",
       "org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2239)\n",
       "org.apache.spark.SparkContext$.markPartiallyConstructed(SparkContext.scala:2312)\n",
       "org.apache.spark.SparkContext.<init>(SparkContext.scala:91)\n",
       "$line53.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:22)\n",
       "$line53.$read$$iwC$$iwC$$iwC.<init>(<console>:27)\n",
       "$line53.$read$$iwC$$iwC.<init>(<console>:29)\n",
       "$line53.$read$$iwC.<init>(<console>:31)\n",
       "$line53.$read.<init>(<console>:33)\n",
       "$line53.$read$.<init>(<console>:37)\n",
       "$line53.$read$.<clinit>(<console>)\n",
       "$line53.$eval$.<init>(<console>:7)\n",
       "$line53.$eval$.<clinit>(<console>)\n",
       "$line53.$eval.$print(<console>)\n",
       "sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "java.lang.reflect.Method.invoke(Method.java:498)\n",
       "org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)\n",
       "org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1346)\n",
       "org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)\n",
       "org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)\n",
       "org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:361)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1$$anonfun$apply$3.apply(ScalaInterpreter.scala:356)\n",
       "org.apache.toree.global.StreamState$.withStreams(StreamState.scala:81)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
       "org.apache.toree.kernel.interpreter.scala.ScalaInterpreter$$anonfun$interpretAddTask$1.apply(ScalaInterpreter.scala:355)\n",
       "org.apache.toree.utils.TaskManager$$anonfun$add$2$$anon$1.run(TaskManager.scala:140)\n",
       "java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n",
       "java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n",
       "java.lang.Thread.run(Thread.java:745)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sc = new SparkContext(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
