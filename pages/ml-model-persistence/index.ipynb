{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Persistence\n",
    "\n",
    "머신러닝 모델을 학습시킨 후, 모델 재사용을 위해 저장하고 로드하는 방법을 알아봅니다. \n",
    "\n",
    "## Scikit-Learn\n",
    "\n",
    "Scikit-Learn 에서는 학습 후 모델을 저장하기 위해 joblib 모듈을 제공해 줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: np_data_xs=(100000, 10), np_data_ys=(100000,)\n",
      "train shape: np_train_xs=(70000, 10), np_train_ys=(70000,)\n",
      "test shape: np_test_xs=(30000, 10), np_test_ys=(30000,)\n",
      "model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='sag',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "classification_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78     10004\n",
      "           1       0.77      0.72      0.74     10004\n",
      "           2       0.88      0.91      0.89      9992\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     30000\n",
      "   macro avg       0.81      0.81      0.81     30000\n",
      "weighted avg       0.81      0.81      0.81     30000\n",
      "\n",
      "classification_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78     10004\n",
      "           1       0.77      0.72      0.74     10004\n",
      "           2       0.88      0.91      0.89      9992\n",
      "\n",
      "   micro avg       0.81      0.81      0.81     30000\n",
      "   macro avg       0.81      0.81      0.81     30000\n",
      "weighted avg       0.81      0.81      0.81     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets, model_selection, linear_model, metrics\n",
    "import os, joblib\n",
    "\n",
    "# 데이터\n",
    "np.random.seed(0)\n",
    "n_samples = 100000\n",
    "np_data_xs, np_data_ys = datasets.make_classification(\n",
    "    n_samples=n_samples, # 데이터 수\n",
    "    n_features=10, # X feature 수\n",
    "    n_informative=3,\n",
    "    n_classes=3, # Y class 수\n",
    "    random_state=0) # 난수 발생용 Seed 값\n",
    "print(\"data shape: np_data_xs={}, np_data_ys={}\".format(np_data_xs.shape, np_data_ys.shape))\n",
    "np_train_xs, np_test_xs, np_train_ys, np_test_ys = model_selection.train_test_split(\n",
    "    np_data_xs, np_data_ys, \n",
    "    test_size=0.3, shuffle=True, random_state=2)\n",
    "print(\"train shape: np_train_xs={}, np_train_ys={}\".format(np_train_xs.shape, np_train_ys.shape))\n",
    "print(\"test shape: np_test_xs={}, np_test_ys={}\".format(np_test_xs.shape, np_test_ys.shape))\n",
    "\n",
    "# 모델\n",
    "model = linear_model.LogisticRegression(solver='sag', multi_class='multinomial')\n",
    "\n",
    "# 학습\n",
    "print(\"model={}\".format(model))\n",
    "model.fit(np_train_xs, np_train_ys)\n",
    "\n",
    "# 평가\n",
    "np_pred_ys = model.predict(np_test_xs)\n",
    "cr = metrics.classification_report(np_test_ys, np_pred_ys)\n",
    "print(\"classification_report\\n\", cr)\n",
    "\n",
    "# 모델 저장/로드\n",
    "path_model = \"/tmp/model.joblib\"\n",
    "joblib.dump(model, path_model)\n",
    "model = joblib.load(path_model)\n",
    "\n",
    "# 재평가\n",
    "np_pred_ys = model.predict(np_test_xs)\n",
    "cr = metrics.classification_report(np_test_ys, np_pred_ys)\n",
    "print(\"classification_report\\n\", cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras\n",
    "\n",
    "Keras에서 학습한 모델을 저장하고 불러오는 방법을 알아봅니다.\n",
    "\n",
    "참조: https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model\n",
    "\n",
    "### 전체 모델 저장하기/불러오기 (architecture + weights + optimizer state)\n",
    "\n",
    "모델을 하나의 HD5 파일 형식으로 하나의 파일에 저장하고 불러올 수 있습니다. 저장되는 정보는 아래와 같습니다.\n",
    "\n",
    "* the architecture of the model, allowing to re-create the model\n",
    "* the weights of the model\n",
    "* the training configuration (loss, optimizer)\n",
    "* the state of the optimizer, allowing to resume training exactly where you left off.\n",
    "\n",
    "```python\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model('my_model.h5')\n",
    "```\n",
    "\n",
    "전체 모델을 저장하고/불러오기 위해서는 Keras의 기본 모델을 이용하여 모델을 생성해야 합니다. 코드의 가독성을 위해 Keras 모델을 상속하여 모델 클래스를 만들어 사용하는 경우는 모델의 가중치 값만을 저장하고 불러올 수 있습니다. 복잡한 모델의 경우는 모델의 구조를 저장하는 것이 유리하기때문에 기본 Keras 클래스를 통해 모델을 생성하는 것을 추천합니다.\n",
    "\n",
    "### 모델 구조만 저장하기/불러오기\n",
    "\n",
    "JSON 또는 YAML 형태로 모델을 저장하고 불러올 수 있습니다.\n",
    "\n",
    "```python\n",
    "from keras.models import model_from_json\n",
    "from keras.models import model_from_yaml\n",
    "\n",
    "# JSON\n",
    "json_string = model.to_json()\n",
    "model = model_from_json(json_string)\n",
    "\n",
    "# YAML\n",
    "yaml_string = model.to_yaml()\n",
    "model = model_from_yaml(yaml_string)\n",
    "```\n",
    "\n",
    "### 모델 가중치만 저장하기/불러오기\n",
    "\n",
    "모델을 학습시킨 결과 가중치만 HDF5 형식으로 저장하고 불러올 수 있습니다. 저장된 가중치를 사용하기 위해서는 저장한 모델의 구조가 동일해야 합니다\n",
    "\n",
    "```python\n",
    "model.save_weights('my_model_weights.h5')\n",
    "model.load_weights('my_model_weights.h5')\n",
    "```\n",
    "\n",
    "Fine-tuning 또는 Transfer-learning 과 같이 불러온 가중치를 다른 모델에서 사용해야 할 경우에는 layer 의 이름을 통해 해당 layer 의 가중치만 불러오기도 가능합니다.\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "Assuming the original model looks like this:\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2, input_dim=3, name='dense_1'))\n",
    "    model.add(Dense(3, name='dense_2'))\n",
    "    ...\n",
    "    model.save_weights(fname)\n",
    "\"\"\"\n",
    "\n",
    "# new model\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=3, name='dense_1'))  # will be loaded\n",
    "model.add(Dense(10, name='new_dense'))  # will not be loaded\n",
    "\n",
    "# load weights from first model; will only affect the first layer, dense_1.\n",
    "model.load_weights(fname, by_name=True)\n",
    "```\n",
    "\n",
    "### 모델에 custom layers (or other custom objects) 포함된 경우\n",
    "\n",
    "자신만의 모델을 위해 custom layer/object/function 를 작성한 경우, 모델을 불러올 때는 해당 정보를 모델에 넘겨 줘야 합니다.\n",
    "\n",
    "```python\n",
    "from keras.models import load_model\n",
    "# Assuming your model includes instance of an \"AttentionLayer\" class\n",
    "model = load_model('my_model.h5', custom_objects={'AttentionLayer': AttentionLayer})\n",
    "\n",
    "from keras.utils import CustomObjectScope\n",
    "# Alternatively, you can use a custom object scope:\n",
    "with CustomObjectScope({'AttentionLayer': AttentionLayer}):\n",
    "    model = load_model('my_model.h5')\n",
    "\n",
    "from keras.models import model_from_json\n",
    "# Custom objects handling works the same way for load_model, model_from_json, model_from_yaml:\n",
    "model = model_from_json(json_string, custom_objects={'AttentionLayer': AttentionLayer})\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: np_data_xs=(10000, 10), np_data_ys=(10000,)\n",
      "train shape: np_train_xs=(7000, 10), np_train_ys=(7000,)\n",
      "test shape: np_test_xs=(3000, 10), np_test_ys=(3000,)\n",
      "\n",
      "model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                176       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 609\n",
      "Trainable params: 609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc=0.92733\n",
      "classification_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91      1021\n",
      "           1       0.92      0.92      0.92      1011\n",
      "           2       0.93      0.97      0.95       968\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      3000\n",
      "   macro avg       0.93      0.93      0.93      3000\n",
      "weighted avg       0.93      0.93      0.93      3000\n",
      "\n",
      "acc=0.92733\n",
      "classification_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91      1021\n",
      "           1       0.92      0.92      0.92      1011\n",
      "           2       0.93      0.97      0.95       968\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      3000\n",
      "   macro avg       0.93      0.93      0.93      3000\n",
      "weighted avg       0.93      0.93      0.93      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets, preprocessing, model_selection, metrics\n",
    "from keras import models, layers, optimizers, utils\n",
    "\n",
    "# 데이터\n",
    "np.random.seed(0)\n",
    "n_samples = 10000\n",
    "n_features = 10\n",
    "n_class = 3\n",
    "np_data_xs, np_data_ys = datasets.make_classification(\n",
    "    n_samples=n_samples, # 데이터 수\n",
    "    n_features=n_features, # X feature 수\n",
    "    n_informative=n_class,\n",
    "    n_classes=3, # Y class 수\n",
    "    random_state=0) # 난수 발생용 Seed 값\n",
    "print(\"data shape: np_data_xs={}, np_data_ys={}\".format(np_data_xs.shape, np_data_ys.shape))\n",
    "np_train_xs, np_test_xs, np_train_ys, np_test_ys = model_selection.train_test_split(\n",
    "    np_data_xs, np_data_ys, \n",
    "    test_size=0.3, shuffle=True, random_state=2)\n",
    "print(\"train shape: np_train_xs={}, np_train_ys={}\".format(np_train_xs.shape, np_train_ys.shape))\n",
    "print(\"test shape: np_test_xs={}, np_test_ys={}\".format(np_test_xs.shape, np_test_ys.shape))\n",
    "\n",
    "# 전처리\n",
    "scaler_xs = preprocessing.StandardScaler()\n",
    "np_train_scale_xs = scaler_xs.fit_transform(np_train_xs)\n",
    "np_test_scale_xs = scaler_xs.transform(np_test_xs)\n",
    "\n",
    "np_train_onehot_ys = utils.np_utils.to_categorical(np_train_ys, n_class)\n",
    "np_test_onehot_ys = utils.np_utils.to_categorical(np_test_ys, n_class)\n",
    "\n",
    "# 모델\n",
    "def create_dnn(n_i, n_hs, n_o):\n",
    "    m = models.Sequential()    \n",
    "    m.add(layers.Dense(n_i, activation='relu', input_shape=(n_i,)))\n",
    "    for l, n_h in enumerate(n_hs):\n",
    "        m.add(layers.Dense(n_h, activation='relu'))\n",
    "    m.add(layers.Dense(n_o, activation = 'softmax'))\n",
    "    sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    m.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return m\n",
    "\n",
    "model = create_dnn(n_i = n_features, n_hs = [16, 16], n_o = n_class)\n",
    "\n",
    "# 학습\n",
    "print(\"\\nmodel\")\n",
    "model.summary()\n",
    "history = model.fit(np_train_scale_xs, np_train_onehot_ys, epochs=10, batch_size=10, verbose=0)\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['acc'], label='acc')    \n",
    "plt.legend()\n",
    "plt.show()    \n",
    "\n",
    "# 평가\n",
    "np_pred_ys = model.predict_classes(np_test_scale_xs)\n",
    "\n",
    "acc = metrics.accuracy_score(np_test_ys, np_pred_ys)\n",
    "print(\"acc={:.5f}\".format(acc))\n",
    "\n",
    "cr = metrics.classification_report(np_test_ys, np_pred_ys)\n",
    "print(\"classification_report\\n\", cr)\n",
    "\n",
    "# 모델 저장/로드\n",
    "model.save('/tmp/my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "del model  # deletes the existing model\n",
    "\n",
    "model = models.load_model('/tmp/my_model.h5')\n",
    "\n",
    "# 재평가\n",
    "np_pred_ys = model.predict_classes(np_test_scale_xs)\n",
    "\n",
    "acc = metrics.accuracy_score(np_test_ys, np_pred_ys)\n",
    "print(\"acc={:.5f}\".format(acc))\n",
    "\n",
    "cr = metrics.classification_report(np_test_ys, np_pred_ys)\n",
    "print(\"classification_report\\n\", cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nikola": {
   "category": "",
   "date": "2019-05-11",
   "description": "",
   "link": "",
   "slug": "ml-model-persistence",
   "tags": "",
   "title": "Machine Learning - Model Persistence",
   "type": "text"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
